## 第三章 存储器

### 3.1 本章大纲要求与核心考点

#### 3.1.1 大纲内容

（一）存储器的分类

（二）层次化存储器的基本结构

（三）半导体随机存储器

1. SRAM 存储器
2. DRAM 存储器
3. Flash 存储器

（四）主存储器

1. DRAM 芯片和内存条
2. 多模块存储器
3. 主存和CPU之间的连接

（五）外部存储器

1. 磁盘存储器
2. 固态硬盘（SSD）

（六）高速缓冲存储器（Cache）

1. Cache 的基本工作原理
2. Cache 和主存之间的映射方式
3. Cache 中主存块的替换算法
4. Cache 写策略

（七）虚拟存储器

1. 虚拟存储器的基本概念

2. 页式虚拟存储器

   基本原理，页表，地址转换，TLB（快表）

3. 段式虚拟存储器

4. 段页式虚拟存储器

#### 3.1.2 核心考点

​        本章内容是考研考察的一个重点和难点，往往会有综合应用题出现。

​        需要重点掌握的内容包括：

- 半导体存储芯片的特性、工作原理、扩展技术及与 CPU 的连接，多模块存储器的原理。
- 磁盘存储器的原理、特点、性能指标，RAID 的原理，固态硬盘的特点和原理。
- 程序访问的局部性原理，Cache 的工作原理及性能计算，Cache 和主存的三种映射方式的原理、 特点、地址结构、访存过程，Cache 替换算法（常考 LRU） , Cache 写策略，Cache 块中的标记项。
- 虚拟存储器的基本原理，页表机制（二级页表结合操作系统考查），快表的原理，具有快表和 Cache 的多级页式存储系统的工作原理（综合性较强），段式和段页式虚拟存储器的基本原理。

#### 3.1.3 真题分布

  <table style="text-align:center">
      <tr>
          <th rowspan="2">考点</th>
          <th colspan="2">考查次数</th>
      </tr>
      <tr>
          <th>单项选择题</th>
          <th>综合应用题</th>
      </tr>
      <tr>
          <td>高速缓冲存储器（Cache）</td>
          <td>12</td>
          <td>9</td>
      </tr>
      <tr>
          <td>虚拟存储器</td>
          <td>5</td>
          <td>9</td>
      </tr>
      <tr>
          <td>半导体存储器</td>
          <td>6</td>
          <td>1</td>
      </tr>
      <tr>
          <td>主存的扩展及与 CPU 的连接</td>
          <td>6</td>
          <td>1</td>
      </tr>
      <tr>
          <td>磁盘存储器</td>
          <td>4</td>
          <td>0</td>
      </tr>     
      <tr>
          <td>低位交叉存储器</td>
          <td>2</td>
          <td>1</td>
      </tr>
  </table>






***

### 3.2 存储器概述

#### 3.2.1 存储器的分类

​		存储器是计算机系统中的记忆设备，用来存放程序和数据。存储器的种类繁多，从不同的角度对存储器可作不同的分类。

![](E:\source\jk-english\英语语法初级\图片\3_1_存储器不同角度的分类.png)

##### 1. 按存储介质分类

​		存储介质是指能寄存“0”、“1”两种代码并能区别两种状态的物质或元器件。存储介质主要有半导体器件、磁性材料和光盘等。

- **半导体存储器**

​		存储元件由半导体器件组成的存储器称为半导体存储器。现代半导体存储器都用超大规模集成电路工艺制成芯片，其优点是体积小、功耗低、存取时间短。

​		半导体存储器又可按其材料的不同， 分为双极型（TTL）半导体存储器和 MOS 半导体存储器两种。前者具有高速的特点；后者具有高集成度的特点，并且制造简单，成本低廉，功耗小，所以 MOS 半导体存储器被广泛用。

- **磁性材料存储器**

​		磁性材料存储器主要依靠磁性材料作为记录的介质，是不易失的永久记忆存储器。又可以分为磁表面存储器和磁芯存储器。

​		磁表面存储器是在金属或塑料基体的表面上涂一层磁性材料作为记录介质，工作时磁层随载磁体高速运转，用磁头在磁层上进行读/写操作，故称为磁表面存储器。按载磁体形状的不同，可分为磁盘、磁带和磁鼓。

​		磁芯是由硬磁材料做成的环状元件，在磁芯中穿有驱动线(通电流)和读出线，这样便可进行读/写操作，这种存储器称为磁芯存储器。磁芯属磁性材料，故它也。不过，磁芯存储器的体积过大、工艺复杂、功耗太大，目前几乎已不被采用。

- **光盘存储器**

​		光盘存储器是应用激光在记录介质（磁光材料）上进行读/写的存储器，具有非易失性的特点。光盘具有记录密度高、耐用性好、可靠性高和可互换性强等特点。

##### 2. 按存取方式分类

​		按存取方式可把存储器分为随机存储器、只读存储器、顺序存取存储器和直接存取存储器。

- **随机存储器**（Random Access Memory， **RAM**）

​		RAM是一种可读/写存储器， 其特点是存储器的任何一个存储单元的内容都可以随机存取，而且存取时间与存储单元的物理位置无关。计算机系统中的主存都采用这种随机存储器。

​		由于存储信息原理的不同， RAM 又分为静态 RAM（以触发器原理寄存信息）和动态 RAM（以电容充放电原理寄存信息）。

- **只读存储器**（Read Only Memory， **ROM**）

​		只读存储器是能对其存储的内容读出，而不能对其重新写人的存储器。这种存储器一旦存入了原始信息后，在程序执行过程中，只能将内部信息读出，而不能随意重新写人新的信息去改变原始信息。

​		所以 ROM 通常用来存放固定不变的程序、常数和汉字字库，甚至用于操作系统的固化。它与随机存储器可共同作为主存的一部分，统一构成主存的地址域。

- **串行访问存储器**

​		如果对存储单元进行读/写操作时，需按其物理位置的先后顺序寻找地址，则这种存储器称为串行访问存储器，也称为顺序存取存储器。显然这种存储器由于信息所在位置不同，使得读/写时间均不相同，比如磁带存储器就是一种顺序存取存储器。

- **直接存取存储器**

​		还有一种属于部分串行访问的存储器，比如磁盘。在对磁盘读/写时，首先直接指出该存储器中的某个小区域(磁道)，然后再顺序寻访，直至找到位置。故其前段是直接访问，后段是串行访问，称为直接存取存储器。

##### 3. 按在计算机中的作用分类

​		按在计算机系统中的作用不同，存储器可以分为主存储器、辅助存储器、缓冲存储器。

- **主存储器**（简称**主存**）：用来存放程序和数据，可以和CPU直接交换信息。

- **辅助存储器**（简称**辅存**）：主存储器的后援存储器， 用来存放当前暂时不用的程序和数据， 它不能与CPU直接交换信息。两者相比，主存速度快、容量小、每位价格高；辅存速度慢、容量大、每位价格低。

- **缓冲存储器**（简称**缓存**，**Cache**） 用在两个速度不同的部件之中。

![](E:\source\jk-english\英语语法初级\图片\3_2_存储器按照计算机中作用的分类.png)


#### 3.2.2 存储器的性能指标

​		存储器有 3 个主要性能指标：速度、容量和每位价格（简称位价）。

##### 1.**存储速度**

​	（1）**存取时间**

​		要想衡量存储速度，最直观的指标就是完成一次存储器读/写操作所需要的时间，这叫做 **存取时间**，又称为 **访问时间**（Memory Access Time）。

​		存取时间又分为读出时间和写入时间。读出时间是从存储器接受到有效地址开始，到产生有效输出所需的全部时间；写入时间是从存储器接受到有效地址开始，到数据写入被选中存储单元为止的全部时间。

​	（2）**存储器周期**

​		**存储器周期** （Memory Cycle Time）指连续进行两次独立的存储器操作（读或者写）需要的最小时间间隔，也叫 **存取周期**。需要注意的是，存储器周期并不等同于完成一次读写操作的时间，而是要更大；因为存储器经过一次读写操作后，并不能立即进行下一次读写，中间还需要一段时间来恢复内部状态。所以，

​															存储器周期 = 存取时间 + 恢复时间

​	（3）**存储器带宽**

​		一般来说，存储器周期越短，存储器的速度就越快；这前提是存储器的每次读写操作处理的数据位数相同。通常情况下，存储器每次读写的位数是跟存储字长相关的，字长越长，一个存取周期处理的数据就越多。

​		所以可以用 **数据传输率** 来表示存储速度，而 **存储器带宽** 就是衡量数据传输率重要指标。存储器带宽指单位时间内存储器存取的数据量。单位为位/秒（b/s），或者字节/秒（B/s）、字/秒。

​															存储器带宽 = 数据宽度 / 存储周期

​		例如，存储器周期为 500 ns，每个存取周期可以访问 16 位，那么带宽就是：

​																16 bit ÷ 500 ns = 32 Mb/s

##### 2. 存储容量

​		存储容量指存储器能存放的数据总量，一般用二进制代码的总位数（bit）来表示。

​													存储容量 = 存储字数 × 存储字长

​		存储字数代表了存储器地址空间的大小，由地址线的位数决定。容量一般也可以用字节总数（Byte）来表示，也就是：

​											存储容量（字节数） = 存储字数 × 存储字长 / 8

​		例如，某机器存储字长为 8 位，地址线有 28 位，那么它的主存最大存储容量为：

​														2^28^ × 8 / 8 = 2^28^ B = 256 MB

##### 3. 位价

​		每位价格也就是存储器的单位成本。

​													位价 = 总成本 / 总容量

​		一般来说，速度越高，位价就越高；容量越大，位价就越低；而且容量越大，速度也会越低。

#### 3.2.3 层次化存储器的基本结构

​		最理想的存储器应该同时满足大容量、高速度、低位价，可惜这是很难达到的。

![](E:\source\jk-english\英语语法初级\图片\3_3_存储器层级金字塔.png)

​		上面列出了不同层级的存储器。由上至下， 位价越来越低，速度越来越慢，容量越来越大，CPU 访问的频度也越来越少。

- 寄存器通常都制作在 CPU 芯片内。寄存器中的数直接在 CPU 内部参与运算， CPU 内可以有十几个、几十个寄存器，它们的速度最快，位价最高，容量最小。
- 主存用来存放将要参与运行的程序和数据，它与 CPU 速度差距较大。
- 为了使主存和 CPU 之间速度更好地匹配， 需要在主存与 CPU 之间插入一种比主存速度更快、容量更小的高速缓冲存储器 Cache，其位价要高于主存。

​		以上三类存储器都是由速度不同、位价不等的半导体存储材料制成的，它们都设在主机内。现代计算机将 Cache 也制作在 CPU 内。

​		磁盘、磁带属于辅存，其容量比主存大得多，大都用来存放暂时未用到的程序和数据文件。CPU不能直接访问辅存， 辅存只能与主存交换信息， 因此辅存的速度可以比主存慢得多。

​		存储系统的层次结构主要体现在缓存-主存和主存-辅存这两个存储层次上。显然， CPU 和缓存、主存都能直接交换信息； 缓存能直接和 CPU、主存交换信息； 而主存可以和 CPU、缓存、辅存交换信息。

![](E:\source\jk-english\英语语法初级\图片\3_4_存储器层次结构.png)

- 缓存-主存层次

​		这一层次主要解决 CPU 和主存速度不匹配的问题。由于缓存的速度比主存的速度高， 只要将CPU近期要用的信息调人缓存， CPU 便可以直接从缓存中获取信息， 从而提高访存速度。但由于缓存的容量小，因此需不断地将主存的内容调入缓存，使缓存中原来的信息被替换掉。主存和缓存之间的数据调动是由硬件自动完成的，对程序员是透明的。

- 主存-辅存层次

​		这一层次主要解决存储系统的容量问题。辅存的速度比主存的速度低，而且不能和 CPU 直接交换信息， 但它的容量比主存大得多， 可以存放大量暂时未用到的信息。当CPU需要用到这些信息时， 再将辅存的内容调人主存， 供CPU直接访问。主存和辅存之间的数据调动是由硬件和操作系统共同完成的。

​		在主存-辅存这一层次的不断发展中，逐渐形成了虚拟存储系统。主存和辅存共同构成了虚拟存储器，二者在硬件和系统软件的共同管理下工作。

​		从CPU角度来看， 缓存-主存这一层次的速度接近于缓存， 高于主存； 其容量和位价却接近于主存。主存-辅存这一层次，从整体分析，其速度接近于主存，容量接近于辅存，平均位价也接近于低速、廉价的辅存位价。这就解决了速度、容量、成本这三者的矛盾。现代的计算机系统几乎都具有这两个存储层次，构成了缓存、主存、辅存三级存储系统。

### 3.3 半导体存储器

​		半导体存储器分为 **随机存取存储器（RAM）**和 **只读存储器（ROM）**。

​		RAM 是一种可读/写存储器，其特点是存储器的任何一个存储单元的内容都可以随机存取，而且存取时间与存储单元的物理位置无关。计算机系统中的主存都采用这种随机存储器。

​		RAM 按照存储信息的原理不同，又可以分为静态随机存取存储器**（SRAM）**和动态随机存取存储器**（DRAM）**，主存储器主要由 DRAM 实现，靠近处理器的那一层缓存 **（Cache）**则由 SRAM 实现，它们都是易失性存储器。ROM 是非易失性存储器。

![](E:\source\jk-english\英语语法初级\图片\3_5_存储芯片Intel6264.png)					![](E:\source\jk-english\英语语法初级\图片\3_5_存储芯片Intel6264引脚图.png)   

​		采用超大规模集成电路制造工艺，可以将半导体存储器集成在一个芯片上，一个芯片内主要包括了具有记忆功能的存储矩阵、译码驱动电路和读/写电路等。

![](E:\source\jk-english\英语语法初级\图片\3_6_存储芯片基本结构.png)

​		主存中各个存储单元的空间位置，是由一个地址号来表示的；通过地址总线可以给定一个存储单元的地址号，从而根据地址读出或者写入一个存储字。

- 译码驱动：将地址总线送来的地址信号翻译成对应存储单元的选择信号，该信号在读/写电路的配合下完成对被选中单元的读/写操作。
- 读/写电路：包括读出放大器和写入电路，用来完成读/写操作。

​		存储芯片通过地址总线、数据总线和控制总线与外部连接。地址线和数据共同反映了芯片的存储容量。比如，10 根地址线，4 根数据线，表示芯片的存储容量为：2^10^ × 4 = 4 Kb。

- 地址线是单向输入的，其位数与芯片存储容量有关。
- 数据线是双向输入的，其位数与芯片每次可读出或写入的数据位数有关，从而也影响到存储容量。
- 控制线包括了读/写控制线和片选线。读/写控制线决定芯片进行的具体操作，片选线用来选择芯片。不同的存储芯片的控制线可能是不同的，有的芯片读/写控制线是两根（引脚名称一般是 $\overline{OE}$ 和 $\overline{WE}$ ），有的芯片则读/写共用一根（引脚 $\overline{WE}$）；片选线一般是一根（引脚 $\overline{CE}$ 或 $\overline{CS}$），也有可能是两根。

​		半导体存储芯片的译码驱动，主要有两种方式：**线选法** 和 **重合法**。

- 线选法：是用一根字选择线（字线），直接选中一个存储单元的各位。这种方式结构比较简单，不过只适合用于容量不大的存储芯片。
- 重合法：用两个方向的地址，共同决定选中存储矩阵中的一个存储单元。相比 “一维” 的线选法，重合法就升级到了 “二维”，可以用更少的选择线实现对所有存储单元的选择。

![](E:\source\jk-english\英语语法初级\图片\3_7_线选法256×1B存储芯片结构示意图.png)

​		上面是一个采用线选法译码驱动的存储芯片结构示意图。这个芯片有 8 位地址线和 8 位数据线，所以有 2^8^ = 256 个存储字，需要 256 根字线来实现选中每个存储字。

​		如果采用重合法，则可以使用 X、Y 两个方向的地址译码器分别对 4 位地址进行译码，只需要两个方向各 16 根选择线，就可以直接选中 16 × 16 存储矩阵中的每一位。

![](E:\source\jk-english\英语语法初级\图片\3_8_重合法16×16存储芯片结构示意图.png)

​		当然，在这个示例中，如果用重合法实现 256 个字节（256 × 8）的存储器，需要使用 8 片上面结构的芯片，这样一来总的选择线并没有更少。不过如果考虑更大容量的存储器，比如地址线有 32 位、数据线仍为 8 位时，则线选法需要 2^32^ 根字线；而重合法同样是需要 8 片芯片，每片芯片只需 2^16^ × 2 = 2^17^ 根选择线就可以实现。

#### 3.3.1 SRAM

​		通常把存放一个二进制位的物理器件称为存储元，它是存储器最基本的构件。地址码相同的多个存储元构成一个存储单元。存储单元的集合构成存储体。

​		**静态 RAM**（Static RAM，**SRAM**）的存储元是用双稳态触发器（六晶体管MOS）来记忆信息的，因此信息被读出后，它仍保持其原状态而不需要刷新；这种读特性被称为“非破坏性读出”。

![](E:\source\jk-english\英语语法初级\图片\3_9_静态RAM的基本单元电路.png)

​		上图中，T~1~ ~ T~4~ 构成了 MOS 管双稳态触发器基本电路；而 T~5~、T~6~ 受行地址选择信号控制，T~7~、T~8~ 受列地址选择信号控制，它们就像开关，将位线 A’ 、A 与数据线连接起来。由 T~1~ ~ T~6~ 这 6 个 MOS 管构成了静态 RAM 的基本单元电路，T~7~、T~8~ 则不包含在内，它们是芯片内同一列的各个基本单元电路所共有的。

​		下面是 Intel 2114 RAM 芯片的存储矩阵结构示意图。2114 芯片有 10 根地址线，其中 6 根行地址线、4 根列地址线，存储矩阵由 64 × 64 个基本单元电路组成，总容量为 1K × 4 位。

![](E:\source\jk-english\英语语法初级\图片\3_10_Intel2114矩阵存储结构.png)

​		SRAM 使用触发器工作原理存储信息，因此在读出信息后，它仍会保持原来的状态，不需要刷新。不过如果电源掉电，存储的信息就会丢失，所以它属于易失性半导体存储器。

​		SRAM 的存取速度快，但集成度低，功耗较大，价格昂贵，一般用于 Cache。

#### 3.3.2 DRAM

​		**动态 RAM**（Dynamic RAM，**DRAM**）是利用存储元电路中栅极电容上的电荷来存储信息的。若电容上存有足够多的电荷表示存 “1”，电容上无电荷则表示存 “0”。

​		常见的动态 RAM 基本单元电路有三管式和单管式两种。单管式只需要一个 MOS 管和一个电容，因此可以极大地提高集成度。

![](E:\source\jk-english\英语语法初级\图片\3_11_动态RAM的基本单元电路.png)

- 当读取数据时，字线上的高电平使 MOS 管 T 导通，如果电容 C~s~ 有电荷就会在数据线上产生电流，可以看作 “1”；反之如果没有电荷，数据线上就没有电流，看作 “0”。进行读操作之后，电容上的电荷就释放掉了，所以必须进行 “再生” 处理；这种读取方式为 **破坏性读出**。
- 对于写入操作，同样是字线高电平令 T 导通，如果数据线上为高电平则对电容充电，存入 “1”；如果为低电平则电容放电，存 “0”。

​		可以看到，DRAM 的基本存储元可以只使用一个晶体管, 所以它比 SRAM 的密度要高很多。为了进一步提高集成度，DRAM 采用 **地址复用技术**，地址信号分行、列两次传送，这样地址线是原来的一半，地址引脚数也可以减少一半，就能够进一步减小芯片的体积。

​		下面是 Intel 4116 RAM 芯片的整体结构和存储矩阵示意图。4116 芯片的存储矩阵为 128 × 128，共有 16 K 个单管 MOS 基本单元电路，容量为 16K × 1 位。本来芯片应该有 14 根地址线，不过为了减少芯片封装的引脚数，地址线只有 7 根。这就需要将完整的地址信息分成行地址、列地址两部分（各自 7 位），分两次传送。

![](E:\source\jk-english\英语语法初级\图片\3_12_Intel4116芯片基本结构.png)

![](E:\source\jk-english\英语语法初级\图片\3_13_Intel4116矩阵存储结构.png)

​		相对 SRAM 来说，DRAM 具有容易集成、价位低、容量大和功耗低等优点，但 DRAM 的存取速度比 SRAM慢，一般用于大容量的主存系统。

##### DRAM 的刷新

​		由于电容上的电荷一般只能维持1 ~2ms，因此即使电源不掉电，信息也会自动消失。为此，必须在 2ms 内对所有存储单元恢复一次原状态，这个过程称为 **再生** 或者 **刷新**。

​		刷新的过程，实质上是先将原存信息读出，再由刷新放大器形成原信息并重新写入的再生过程。由于存储单元是被随机访问的，有些存储单元可能一直不会被访问，因此其存储的原信息将会慢慢消失。因此，必须进行定时刷新。一般要求在一定的时间内，对动态 RAM 的全部基本单元必须作一次刷新，这个时间称为 **刷新周期**，也叫 **再生周期**，一般取 2ms。

​		通常有三种刷新方式：集中刷新、分散刷新和异步刷新。

​	（1）**集中刷新**

​		在规定的一个刷新周期内，对全部存储单元集中一段时间进行逐行刷新；刷新时必须停止读/写操作。

​		例如，我们有一个芯片的存储矩阵为 128 × 128，它的存取周期为 0.5 μs，刷新周期为 2 ms（4000 个存取周期），那么对它的 128 行存储单元进行集中刷新需要：

​																		0.5 μs × 128 = 64 μs

​		那剩余的 1936 μs（3872个存取周期）就可以用来读/写或者维持信息。由于在这 64 μs 内无法进行读/写操作，所以这段刷新时间被称为 “死时间”，也叫访存 “死区”。死时间占据存取周期的比例 64 μs / 2 ms × 100% = 3.2%，称为死时间率。

![](E:\source\jk-english\英语语法初级\图片\3_14_DRAM 集中刷新时间分布.png)

​	（2）**分散刷新**

​		对每行存储单元的刷新，分散到每个存取周期内完成。这样，每个存储周期 t~C~ 就分成了两段：前半段 t~M~ 用来读/写或者维持信息，后半段 t~R~ 用来刷新。所以：

​																					t~C~ = t~M~ + t~R~

​		同样以 128 × 128 存储矩阵的芯片为例，读/写周期 t~M~ = t~R~ = 0.5 μs，那么存取周期 t~C~ = 1 μs。逐行进行刷新，每隔 128 μs 就可以将存储芯片全部刷新一遍。

![](E:\source\jk-english\英语语法初级\图片\3_15_DRAM 分散刷新时间分布.png)

​		这样的好处是不存在停止读/写操作的死时间，而且刷新间隔比要求的刷新周期 2ms 短得多；缺点在于存取周期 t~C~ 变长了，使得整个系统速度变慢。 

​	（3）**异步刷新**

​		异步刷新是前两种方式的结合，它既可以缩短 “死时间”，又能充分利用最大的刷新间隔 2ms。

​		还是之前的例子，对于 128 × 128 存储矩阵的芯片，存取周期 t~C~ = 0.5 μs，可以让它把对 128 行的刷新平均分配到 2ms 的刷新周期内。也就是说，每隔 2ms ÷ 128 ≈ 15.6 μs 刷新一行，每次刷新的时间还是一个存取周期 t~R~ = 0.5 μs。

​		![](E:\source\jk-english\英语语法初级\图片\3_16_DRAM 异步刷新时间分布.png)

​		这样一来，2ms 内用于刷新的时间仍然是 128 t~R~ = 64 μs，而由于分散到了整个刷新周期内，每次刷新一行只停了一个存取周期；所以对于每行来说，刷新的间隔还是 2ms，而 “死时间” 缩短为 0.5 μs。

​		如果将 DRAM 的刷新安排在 CPU 对指令的译码阶段，由于这个阶段 CPU 不会访问存储器，所以这样就完全避免了 “死时间” 的问题，从根本上提高了机器效率。

##### DRAM 和 SRAM 的比较

​		目前，随着 DRAM 的容量不断扩大，速度不断提高，它的应用要比 SRAM 更加广泛。DRAM 主要用在计算机的主存中，而 SRAM 通常用于容量不大的高速缓存（Cache）中。

​		两者的特点可以比较如下：

​		![](E:\source\jk-english\英语语法初级\图片\3_17_DRAM vs SRAM.png)

#### 3.3.3 ROM

​		ROM （Read Only Memory）最原始的定义是 “只读存储器”，一旦写入原始信息后就不能更改。所以ROM 通常用来存放固定不变的程序、常数和汉字字库，甚至用于操作系统的固化。它与随机存储器可共同作为主存的一部分，统一构成主存的地址域。

​		不过随着用户的需要和技术的发展，又出现了更多类型的 ROM，让用户拥有了修改数据的能力。

​		根据制造工艺不同，ROM 可分为固定掩模型 ROM（**MROM**）、一次可改写 ROM （**PROM**）、紫外线擦除电可编程 ROM（**EPROM**）、电擦除电可编程 ROM （**EEPROM**）、快擦写**（Flash）**存储器。

​		早期只读存储器的存储内容根据用户要求，厂家采用掩模工艺，把原始信息记录在芯片中，一旦制成后无法更改， 称为掩模型只读存储器（Masked ROM， MROM）。随着半导体技术的发展和用户需求的变化， 只读存储器先后派生出可编程只读存储器（Programmable ROM， PROM）、可擦除可编程只读存储器（Erasable Programmable ROM， EPROM）以及用电可擦除可编程只读存储器（Electrically Erasable Programmable ROM， EEPROM）。到 20 世纪 80 年代，又出现了闪速存储器 （Flash Memory）， 它具有 EEPROM 的特点， 而速度比 EEPROM 快得多。

##### Flash

​		闪速存储器（闪存，**Flash**），又称快擦型存储器，是在 **EEPROM** 的工艺基础上发展而来的，性价比更好、可靠性更高。其主要特点有：

- 价格便宜、集成度高；
- 属非易失性存储器，适合长期保存信息；
- 能快速擦写（电可擦除），写入前必须先擦除，因此写比读要慢。

​		由于 Flash 的擦除、重写时间已经非常短，比一般的 EEPROM 要快得多，所以 Flash 已经具备了 RAM 的功能，可以与 CPU 直接相连。电脑的 BIOS 程序由于包含了开机后的自检程序和自举装载程序，一般都会固化到主板上的一个 ROM 芯片中；如今的电脑通常就会用 Flash 芯片来存放 BIOS 程序。

​		Flash 可以至少擦写 10000 次以上，而且是非易失性存储器，所以在需要周期性修改存储信息、并长期保存的场合，它是一个非常理想的存储器；比如工控系统、单片机中作为数据采集和存储器件，用于制作 U 盘和移动硬盘等。

​		目前随着闪存技术的发展，容量越来越大、价格越来越低，让大容量 Flash 取代磁盘成为了可能。用闪存技术做成 **固态硬盘（SSD）**，可以代替传统的磁盘，速度更快，功耗更低，体积更小。如今很多笔记本电脑中都使用了 SSD，使得计算机平均无故障时间大大延长。

​		**SRAM**、**DRAM** 和 **ROM** 这 3 种存储器的特点可以总结如下。

![](E:\source\jk-english\英语语法初级\图片\3_18_SRAM vs DRAM vs ROM.png)


### 3.4 主存储器

#### 3.4.1 主存储器的基本组成

​		主存储器简称主存或内存，是计算机中存储程序和数据的重要部件。主存内包含了存储体、各种逻辑部件以及控制电路等。

​		主存是通过按地址访问的方式，对存储体内的存储单元进行读写操作的。因此主存首先需要从 MAR 中获取地址，由译码器进行地址译码、再经过驱动电路，进而通过选择线选中所需访问的单元。读出时，需要经过读出放大器才能将被选中存储单元的内容送到 MDR；写入时，MDR 中的数据也需要经过写入电路才能真正存入被选中的单元。所以主存实际结构的基本组成如下：

![](E:\source\jk-english\英语语法初级\图片\3_19_主存基本组成实际结构.png)

​		译码器、驱动器和读写电路都集成在 DRAM 存储芯片中，而 MAR 和 MDR 则集成在 CPU 芯片内。存储芯片可以通过总线与 CPU 相连。

![](E:\source\jk-english\英语语法初级\图片\3_20_主存与CPU的联系.png)

​		当要从主存中读某个数据字时，首先由 CPU 将字的地址送到 MAR，通过地址总线送至主存，然后发出读命令；主存的译码器将地址总线送来的地址译码，导通对应存储单元的选择线，收到读信号后，便将该单元的内容送到数据总线上，进而交给 MDR。

​		如果要向主存写入一个数据字，仍然需要 CPU 先把地址送到 MAR，并把要写的数据送到 MDR，然后发出写命令；主存译码器依然从地址总线读取地址进行译码，接到写命令后，就把数据线上的信息写入对应的存储单元。

##### 译码器（复习）

​		译码器是一种具有 “翻译” 功能的组合逻辑电路器件，可以将以二进制码表示的输入状态，转换成对应的特定输出信号。“译码” 就是 “编码” 的逆过程。

​		对于 n 位信号输入，译码器对应有 2^n^ 个输出。译码器可以用逻辑门电路很容易实现。

![](E:\source\jk-english\英语语法初级\图片\3_21_译码器.png)

​		存储器中的地址译码器，就是以 n 位地址线作为输入，以 2^n^ 根选择线作为输出的译码器。当输入一个地址信号时，地址可以看作一个二进制数，它对应的十进制数就是选择线的序号。

##### 主存中地址的分配

​		主存中各存储单元的空间位置，都是由存储单元的地址号表示的；地址总线的作用就是给出要访问的存储单元的地址。每次访问存储单元，可以读出或者写入一个存储字。

​		存储字长必须是字节（8位）的整数倍，不同机器的存储字长不同。计算机一般既可以按字来寻址，也可以按字节寻址。例如，一台机器的存储字长为 32 位，并且可以按字节寻址，那么它的每个存储字都包含了 4 个具有独立地址的字节，地址的分配方式如下：

​						![](E:\source\jk-english\英语语法初级\图片\3_22_字节寻址的主存地址分配.png)

​		字地址是用该字高位字节的地址来表示，所以字地址总是 4 的整数倍，即二进制末两位总是 0。这样，对于同一个字内的字节，可以用地址末两位来进行区分，高位则是完全相同的。

​		如果这台机器的地址线为 24 位，那么按字节寻址的范围是 2^24^ = 16M，按字寻址的范围为 16M / 4 = 4 M。

#### 3.4.2 主存和 CPU 之间的连接

​		现代计算机的主存都由半导体集成电路构成，一般使用 DRAM 芯片。单个芯片的容量不可能很大，通过存储器芯片扩展技术，将多个芯片集成在一个 **内存条**上，然后由多个内存条及主板上的 ROM 芯片组成计算机所需的主存空间，再通过总线与 CPU 相连。

![](E:\source\jk-english\英语语法初级\图片\3_23_内存条上的存储芯片.png)

​		早期的内存就只是一块芯片，直接焊接在主板上；这样很难拆卸、更换，无法轻易扩容升级。**内存条** 的出现使得内存的更换和升级更加方便。内存条的主体是一块印制电路板（PCB），上面一般焊有多个内存芯片。通过印制板边缘的一排金色引脚（“金手指”）可以很容易地插入主板上的内存插槽，与 CPU 进行连接和数据交换。

##### 1. 主存容量扩展

​		单片存储芯片的容量有限，很难满足我们实际应用的需要，所以主存一般不会直接使用单个芯片实现，而是需要将多个存储芯片连在一起扩展成更大的存储器。这称为 **存储容量的扩展**，主要的方法有 **位扩展** 和 **字扩展**。

**（1）位扩展**

​		位扩展是指对字长进行扩展，也就是增加存储字长。这种情况下，系统地址线位数等于芯片地址线位数，而系统数据线位数多于芯片数据线位数。

​		位扩展的连接方式：各芯片的地址线、片选线和读写控制线与系统总线相应 **并联**；各芯片的 **数据线单独引出**，分别连接系统数据线。各芯片同时工作。

​		以之前介绍过的 SRAM 芯片 2114 为例，它的存储容量为 1K × 4，那么用 2 片 2114 采用位扩展的方式可以组成 1K × 8 的存储器。如下所示：

​				![](E:\source\jk-english\英语语法初级\图片\3_24_2114位扩展.png)

**（2）字扩展**  

​		字扩展是指对存储字的数量进行扩展，而存储字的位数满足系统要求。这种情况下，系统数据线位数等于芯片数据线位数，系统地址线位数多于芯片地址线位数。

​		字扩展的连接方式：各芯片的地址线与系统地址线的 **低位对应相连**，芯片的数据线和读写控制线与系统总线相应 **并联**；由系统地址线的 **高位译码** 得到各芯片的片选信号。各芯片分时工作，同一时间只能有一个芯片被选中。

​		例如，用 2 片容量为 1K × 4 的 2114 芯片，采用字扩展的方式可以组成 2K × 4 的存储器。如下所示：

![](E:\source\jk-english\英语语法初级\图片\3_25_2114字扩展.png)

​		扩展之后的地址线为 11 位，共有 2^11^ = 2 K 个地址。其中：

- 第一片 2114 的地址范围为 **0**00 0000 0000 ~ **0**11 1111 1111；
- 第二片 2114 的地址范围为 **1**00 0000 0000 ~ **1**11 1111 1111。

 （3）字和位同时扩展

​		字和位同时扩展是前两种扩展的组合，这种方式既增加存储字的数量，又增加存储字长。

​		字和位同时扩展的连接方式：将进行位扩展的芯片作为一组，各组的连接方式与位扩展相同；由系统地址线高位译码产生若干个片选信号，分别接到各组芯片的片选信号。

​		例如，用 8 片容量为 1K × 4 的 2114 芯片，字和位同时扩展之后可以组成 4K × 8 的存储器。如下所示：

![](E:\source\jk-english\英语语法初级\图片\3_26_2114字位同时扩展.png)

​		扩展之后的地址线为 12 位，共有 2^12^ = 4 K 个地址。其中：

- 第一、二片 2114 通过位扩展构成第一组，地址范围为 **00**00 0000 0000 ~ **00**11 1111 1111；
- 第三、四片 2114 通过位扩展构成第二组，地址范围为 **01**00 0000 0000 ~ **01**11 1111 1111；
- 第五、六片 2114 通过位扩展构成第三组，地址范围为 **10**00 0000 0000 ~ **10**11 1111 1111；
- 第七、八片 2114 通过位扩展构成第四组，地址范围为 **11**00 0000 0000 ~ **11**11 1111 1111。

##### 2. 主存与CPU的连接

（1）合理选择存储芯片。通常选用 ROM 存放系统程序，选用 RAM 组成用户区。

（2）地址线的连接。CPU 地址线的低位与存储芯片的地址线相连，以选择芯片中的某一单元（字选）；CPU 地址线的高位在扩充存储芯片时用，以选择存储芯片（片选）。

（3）数据线的连接。比较CPU的数据线数与存储芯片的数据位数。如果相等可以直接相连；如果不等，必须对存储芯片进行扩位，使其数据位数与 CPU 的数据线数量相等。

（4）读/写命令线的连接。CPU 的读/写命令线一般可以直接与存储芯片的读/写控制端相连。

（5）片选线的连接。片选信号一般由系统地址线高位译码，它是主存与 CPU 连接的关键。

#### 3.4.3 多模块存储器

​		随着计算机技术的发展，处理的信息量越来越多，对存储器的速度和容量要求也越来越高；而且随着 CPU 性能的不断提升、I/O 设备数量不断增加，导致主存的存取速度已经成为了整个计算机系统的性能瓶颈。这就要求我们必须提高主存的访存速度。

​		基本的想法是寻找更加高速的元器件和存储芯片，或者采用层级结构、加入高速缓存；除此之外，调整主存的结构也可以提高访问速度。这就是所谓的 **多模块存储器**。

##### 1. 单体多字存储器

​		在主存中，程序和数据是连续存放的，所以 CPU 访存取出的信息也是连续的。如果将存储器的存储单元进行扩展，让它能够存储更多的字，那么就可以在一个存取周期内，从同一地址取出更多的指令。将多条指令逐条送至 CPU 执行，由于 CPU 的速度远高于主存，这样就相当于增大了主存的带宽，提高了速度。

​		这种方式是对单独的存储器进行了扩展，类似于位扩展的思路，不过是将一个地址对应的数据扩展到了多个存储字。所以这种结构的存储器称为 **单体多字存储器**。

​		例如，对于一个单体四字存储器，可以在一个存取周期取出四个字的信息。假设指令字长就是一个存储字，那么原先一个存取周期拿到一条指令，现在就可以拿到 4 条；逐条传给 CPU 进行处理，就相当于每隔 1/4 周期，主存就向 CPU 传送了一条指令，带宽变成了 4 倍。

​		![](E:\source\jk-english\英语语法初级\图片\3_27_单体四字结构存储器.png)

- 结构特点：存储器中只有一个存储体，每个存储单元存储 m 个字，总线宽度也为 m 个字。
- 访问方式：一次并行读出 m 个字，地址必须顺序排列并处于同一存储单元。

- 优点：宽度为单体单字存储器的近 m 倍（访问的内容在同一行时）。
- 缺点：如果出现访问冲突（需要的内容不在同一行）或遇到转移指令，效率会显著降低。

##### 2. 多体并行系统

​		另一种思路是采用多模块组成存储器，各个模块可以并行读写，这就是多体并行系统。每个模块有相同的容量和存取速度，各模块都有自己独立的地址寄存器（MAR）、数据寄存器（MDR）、地址译码、驱动电路和读/写电路，它们能并行工作，也能交叉工作。

​		所谓的 “并行工作”，就是 CPU 可以同时访问 N 个模块，同时启动，同时读出；当然，由于总线是公共的，同时读出的 N 个字需要在总线上分时传送。

​		根据对这 N 个模块中存储单元的不同编址方式，多体并行系统又可以分为 **多体高位交叉存储器** 和 **多体低位交叉存储器**。

**（1）多体高位交叉存储器**

​		多体高位交叉存储器中，各模块采用 **高位交叉方式编址**。

​		高位交叉方式编址时，地址分为两部分，高位地址表示体号，低位地址为体内地址。这种编址方式下，一个模块（也就是 “体”）内的地址是连续的，程序存储时会按照体内地址的顺序存放，也就是先存一个模块，存满之后再存下一个；所以这种方式也叫 “**顺序存储**”。

![](E:\source\jk-english\英语语法初级\图片\3_28_高位交叉编址多体存储器.png)

​		只要调动合理，使不同的请求源同时去访问不同的模块，就可以实现并行工作。比如，CPU 在访问一个模块的同时，外部设备可以以直接存储器访问（DMA）的方式访问另一个模块，这样两个体就是并行工作的。

**（2）多体低位交叉存储器**

​		多体低位交叉存储器中，各模块采用 **低位交叉方式编址**。

​		低位交叉编址是指用主存地址的低位来指明存储器模块，高位指明模块内的字地址。这种编址方式下，连续的地址分布在相邻的模块中，同一模块内的地址是不连续的，因此也叫做 “**交叉存储**”。有 M 个模块的低位交叉编址，又叫 **模 M 编址**。

​		![](E:\source\jk-english\英语语法初级\图片\3_29_低位交叉多体存储器.png)

​		上面是一个模 4 交叉编址的存储器，存储体模块个数为 4，所以第一个模块中所有存储单元的地址号，对 4 取模都为 0；同样道理，第二、三、四个模块的地址号，对 4 取模结果分别为 1、2、3。具体的编址地址号如下所示：

![](E:\source\jk-english\英语语法初级\图片\3_30_模4编址地址分布.png)

​		程序按照地址连续存放在相邻模块中，采用低位交叉编址后，可以在不改变每个模块存取周期的前提下，采用 **流水线** 方式并行存取，提高存储器的带宽。

​		在一个存取周期 T 内，m 个模块按一定的顺序分时启动；如果分时启动的时间间隔为 t = T/m，那么在一个存取周期内，CPU 交叉访问各个模块，从而使各模块的读/写操作交错重叠进行，最终向 CPU 可以传送 m 个字。这样，存储器的带宽提升为 m 倍。

​		由于各个模块传送取出的字共享总线，因此假设总线传输周期为 τ，当 t 小于等于 τ 时，就可以获得最大的存储器带宽。所以：

​																				t = T/m ≤ τ

​		所以，对于一个存取周期为 T、总线传输周期为 τ 的机器，设计多体低位交叉存储器时应该有 m ≥ T / τ。一般取最小值即可，在采用流水线方式时应该满足 

​																					T = m τ

​		对于四体低位交叉编址存储器 T = 4 τ，按流水线方式工作时不同模块访问字的时间顺序如下：

​							![](E:\source\jk-english\英语语法初级\图片\3_31_四字低位交叉编址流水线工作时间.png)

​		可以看出，对于流水线工作的低位交叉存储器，连续读取 n 个字所需的时间为：

​																			t~1~ = T + ( n - 1 ) τ 

​		而如果是高位交叉存储器，对应的时间为：

​																					t~2~ = n T

​		对于上面的四字低位交叉存储器，τ = T / 4，所以 t~1~ = ( n + 3 ) T / 4，明显要低于 t~2~；当 n 非常大时，t~1~ 趋近于 T / 4，即速度提升了 4 倍。

​		当然，由于多模块存储器需要同时管理多个存储模块，还要同时处理来自不同部件的访问请求，因此必须增加一个存储器控制部件（简称存控）来处理这些事情。存控可以合理安排各部件请求访问的顺序，并有控制主存读/写操作的功能。

​		因为多模块有额外的开销，所以尽管 m 体低位交叉存储器理论上速度可以达到原先的 m 倍，在实际运行中会有很大差距；而且随着模块数 m 的增大，速度的提升也会越来越不明显。因此实际应用中，最多的情况就是采用 2个模块的二体低位交叉存储器，这就是所谓的 “**双通道内存**” 技术。

​		此外，通过在 DRAM 中引入一个锁存器，可以将 CPU 给出的地址和控制信号锁存，然后在指定的时钟周期后再响应。这样一来，CPU 和主存的数据交互就可以 **同步** 于系统时钟信号，这种存储器就叫做 **同步 DRAM**（Synchronous DRAM，**SDRAM**）。CPU 在发出访问请求后不需要等待，可以在存储器的读取周期内去完成其它操作；等到读取周期（可能需要若干个时钟周期）结束后，CPU 就可以获得从存储器读出的数据了。

​		SDRAM 还支持猝发访问模式，CPU 只要发出一个地址就可以访问连续的一段数据块。SDRAM 芯片内也可以包含多个存储体，构成多体并行系统，提高访问速度。新一代的 SDRAM 可以每周期两次向 CPU 传输数据，因此称为 双倍数据速率 SDRAM（Double Data Rate SDRAM，DDR-SDRAM）。

### 3.5 外部存储器

​		外部存储器是主存的后援设备，也叫做辅助存储器，简称 **外存** 或 **辅存**，与主存一起构成了存储器系统的主存-辅存层次。与主存相比，外存容量大、速度慢、价格低，可以脱机保存信息，属于 **非易失性存储器**。

​		用于计算机系统的外存主要有磁盘、磁带、光盘；磁盘和磁带都属于 **磁表面存储器**。而目前广泛应用的 **固态硬盘（SSD）**主体由闪存芯片构成，属于半导体存储器。

#### 3.5.1 磁盘存储器

​		磁盘是应用最为广泛的外存设备。磁盘根据结构和盘片材质的不同，可以分为 **硬磁盘** 和 **软磁盘**，如今随着存储技术的发展，软磁盘存储器已渐渐不再使用，而硬磁盘存储器依然在外存中占据着重要的比例。

​		磁盘存储器具有外存设备普遍的优缺点：

- 优点：存储容量大，位价低；记录介质可重复使用；记录信息可长期保存而不丢失, 甚至可脱机存档；非破坏性读出，读出时不需要再生。
- 缺点：存取速度慢，机械结构复杂。

##### 1. 磁表面存储器和磁记录原理

​		磁表面存储器在不同形状（盘状、带状）的载体上涂有磁性材料层，这磁层就是记录信息的存储介质。存储器工作时，依靠载体的机械运动，由磁头在磁层上进行读/写操作；信息就记录在磁层上，这些信息的轨迹叫做 **磁道**。磁盘的磁道是一个个同心圆，磁带的磁道则是一条条直线。

​		                       <img src="C:/Users/18133/Desktop/课件/pictures/3_32_磁盘和磁带的磁道.png" style="zoom:65%;" /> 

- 磁记录原理：磁表面存储器在磁头和磁性记录介质做相对运动时，通过电磁转换完成读/写操作。

<img src="C:/Users/18133/Desktop/课件/pictures/3_33_磁表面存储器写入原理.png" style="zoom:70%;" />

<img src="C:/Users/18133/Desktop/课件/pictures/3_33_磁表面存储器读出原理.png" style="zoom:70%;" />

- 磁记录方式：又称为编码方法，就是按某种规律把一连串的二进制信息转换成磁表面相应的磁化状态。通常采用调频制**（FM）**和改进型调频制**（MFM）**的记录方式。	

##### 2. 硬磁盘的分类和基本结构

（1）硬磁盘存储器的类型

​		硬磁盘中的存储载体是盘片，它是由硬质铝合金材料制成的，其表面涂有一层硬磁特性材料，可以被磁化从而完成信息的存储。通过磁头和盘片的相对运动，就可以实现信息的读取和写入。

![](E:\source\jk-english\英语语法初级\图片\3_34_硬磁盘实物图.png)

- 根据能否更换盘片，硬磁盘可以分为 **可换盘磁盘** 和 **固定盘磁盘**。

​		可换盘磁盘的盘片可以脱机保存，所以更换的时候可以只换单片，方便维护和扩容；固定盘磁盘的盘片则不能从驱动器中取下，更换的时候需要整体更换，可靠性更高。

- 按照磁头的工作方式，硬磁盘可以分为 **固定磁头磁盘** 和 **移动磁头磁盘**。

![](E:\source\jk-english\英语语法初级\图片\3_35_固定磁头和移动磁头硬磁盘结构示意图.png)

- 固定磁头的磁盘存储器，磁头位置是固定不动的，磁盘上的每一个磁道都对应着一个磁头，盘片也不可以更换；这样省去了磁头在盘片上移动寻找磁道的时间，存取速度更快。
- 移动磁头的磁盘存储器，存取数据时磁头需要在盘面上做径向运动；这类存储器可以只有一个盘片，也可以有多个盘片。多个盘片会装在一个同心主轴上，每个记录面各有一个磁头。所有这些磁头连成一体，固定在支架上移动；任何时刻所有磁头和主轴的距离都相等，它们位于和圆心相等距离的一组磁道上，这组磁道称为一个 **柱面**。

​		目前，移动磁头的多盘片磁盘存储器应用最广泛，典型代表是 **温切斯特磁盘**。温切斯特磁盘简称温盘，是一种可移动磁头、固定盘片的磁盘存储器。它采用密封组合的方式，将磁头、盘片、驱动部件以及读/写电路等做成一个不可拆卸的整体，称作 **头盘组合体**。所以它的特点是可靠性强，防尘性能好，对环境要求不高。

（2）硬磁盘存储器的组成

​		硬磁盘存储器由磁盘驱动器、磁盘控制器和盘片组成。

![](E:\source\jk-english\英语语法初级\图片\3_36_磁盘存储器基本结构.png)

- **磁盘驱动器**

​		磁盘驱动器是主机之外的一个独立装置，又称作 **磁盘机**。驱动器主要包括主轴、定位驱动和数据控制 3 个部分。

<img src="C:/Users/18133/Desktop/课件/pictures/3_37_磁盘驱动器结构.png" style="zoom:80%;" />

​		主轴受传动机构的控制，可以使磁盘高速旋转；磁头分装在读/写臂上，连接到一个小车，在音圈电机的控制下平行移动进行寻道；定位驱动系统是一个带有速度、位置反馈的闭环自动控制系统，根据磁头的即时位置和速度计算出接下来运动的方向和速度；数据控制部分主要对数据转换和读/写操作进行控制。首先接收选头选址信号，然后根据磁记录方式将数据脉冲和线圈的驱动电流进行转换。

- **磁盘控制器**

​		磁盘控制器是磁盘存储器和主机的接口，通常就是一块电路板，插在主机总线插槽中。它的作用是接收由主机发来的命令，将其转换成磁盘驱动器的控制命令，实现主机和驱动器之间的数据格式转换和数据传送，并且控制驱动器的读/写操作。一个磁盘控制器可以控制多台驱动器。

​		将磁盘控制器的功能全部内置在磁盘设备中，主机和设备之间就可以采用标准的通用接口了。最初这种接口就称为 **IDE**（Integrated Drive Electronics）接口，同时期还有更高性能的 **SCSI**（Small Computer System Interface）接口；之后又发展出了采用串行传输技术的接口，这就是 **SATA**（Serial Advanced Technology Attachment）和 **SAS**（Serial Attached SCSI）。目前我们的个人电脑中，大多都是采用 SATA 接口的硬盘。

- **盘片**

​		盘片是磁盘中存储信息的载体，由驱动器控制它的转动并读/写数据；有时也会直接把盘片当作驱动器的一部分。目前硬盘的盘片正朝着小体积大容量的方向发展，记录密度越来越高。

##### 3. 磁盘的工作原理

（1）磁盘存储区域

​		一块磁盘划分为若干个记录面，每个记录面划分为若干条 **磁道**，而每条磁道又划分为若干个 **扇区**，扇区（也称块、扇段）是磁盘读写的最小单位，即磁盘按块存取。一个具有多盘片的磁盘组，可将其 n 个面上所有同一半径的磁道看成一个圆柱面，称为 **柱面**；在移动磁头的组合盘中，多个磁头一次定位的磁道集合就是一个柱面。	

![](E:\source\jk-english\英语语法初级\图片\3_38_磁道和扇区.png)<img src="C:/Users/18133/Desktop/课件/pictures/3_39_柱面.png" style="zoom:85%;" />

- 磁头数：表示磁盘总共有几个磁头，一般来说一个记录面对应一个磁头，所以等于记录面数。

- 柱面数：表示磁盘中柱面的个数，等于每个记录面上的磁道数。

- 扇区数：表示每条磁道上有几个扇区。


（2）磁盘地址

​		 一个磁盘存储器可以有多台驱动器，不同的驱动器可以用一个编号（驱动器号，或者台号）来区分。当驱动器号确定后，磁盘进行寻址定位时，首先需要整体移动磁头找到对应柱面（磁道）、再选定磁头，最后转动盘片找到扇区。所以寻址所需要的磁盘地址，一般由 **驱动器号**、**柱面（磁道）号**、**盘面号**、**扇区号** 组成。

​		磁盘的地址格式如下所示:

| 驱动器号 | 柱面（磁道）号 | 盘面号 | 扇区号 |
| :------: | :------------: | :----: | :----: |

​		例如，系统中有 4 个驱动器，每个驱动器带一个磁盘组，其中有 11 个盘片（最外层上下侧为保护面），每个盘面有 203 个磁道、划分为 16 个扇区。则可以算出，驱动器号需要 2 位；柱面号需要 8 位（ 2^7^ < 203 < 2^8^ ）；而 11 个盘片有 20 个盘面，所以盘面号需要 5 位；扇区号需要 4 位。最终每个磁盘地址要 19 位二进制代码。

| 驱动器号（2位） | 柱面（磁道）号（8位） | 盘面号（5位） | 扇区号（4位） |
| :-------------: | :-------------------: | :-----------: | :-----------: |

（3）磁盘的工作过程

​		磁盘的主要操作是寻址、读盘、写盘。磁盘属于机械式部件，其读/写操作是串行的，不可能在同一 时刻既读又写，也不可能在同一时刻读两组数据或写两组数据。

##### 4. 磁盘的性能指标

（1）**记录密度**

​		记录密度通常是指单位长度内所存储的二进制信息量。磁盘存储器用 **道密度**、**位密度** 和 **面密度** 来表示。

- 道密度：沿磁盘半径方向单位长度上的磁道数；单位 tpi（Track Per Inch，道每英寸）或 tpm（道每毫米）。为避免电磁干扰，磁道之间会保持一定的距离，称为 道距；道密度就是 D~t~ 就是 道距 P 的倒数：

$$
D_t = \frac{1}{P}
$$

- 位密度：单位长度的磁道上能记录的二进制位数；单位 bpi（Bits Per Inch，位每英寸）。磁盘中每个磁道上记录的信息量是相同的，可以记为每道总位数 f~t~ ；由于各个磁道周长不同，因此位密度也不同。一般所说的磁盘位密度，指的就是最内圈上的位密度（最大位密度）。如果最内圈同心圆的直径为 d~min~，那么位密度 D~b~ 为：

$$
D_b = \frac{f_t}{{\pi}d_{min}}
$$

- 面密度：位密度和道密度的乘积。

（2）**存储容量**

​		存储容量指磁盘能存储的二进制信息的总数量，一般以位或者字节为单位。磁盘存储容量 C 可以计算为：
$$
C = n \times k \times s
$$
​		其中 n 为 盘面数，k 为每个盘面的磁道数，s 为每条磁道上记录的二进制代码数。

​		磁盘有非格式化容量和格式化容量两个指标。非格式化容量是指磁表面可利用的磁化单元总数，可以由道密度和位密度计算得到；格式化容量是指按某种特定的记录格式所能存储信息的总量，即用户可以使用的容量，一般是非格式化容量的 60% ~ 70%。

（3）**平均寻址时间**

​		磁盘的存取方式是直接存取，它的寻址时间分为两个部分：磁头寻找目标磁道的时间 t~s~；和找到磁道后，磁头等待要读写的磁道区段（扇区）旋转到磁头下方的时间 t~w~ 。由于寻找相邻磁道和不相邻磁道的时间不同，磁头等待不同扇区的时间也不同，所以应该取平均值，称为 **平均寻址时间**；它是 **平均寻道时间** t~sa~ 和 **平均等待时间**     t~wa~ 之和。
$$
T_a = t_{sa} + t_{wa} = \frac{t_{smax} + t_{smin}}{2} + \frac{t_{wmax} + t_{wmin}}{2}
$$
​		平均寻址时间再加上数据传输时间，就是磁盘的 **平均访问时间**。

（4）**数据传输率**

​		数据传输率是指单位时间内，磁盘向主机传送数据的位数或字节数。数据传输率 D~r~ 与记录位密度 D~b~ 和磁道运动速度 V 有关；
$$
D_r = D_b \times V
$$
​		对于磁盘来说，“磁道运动速度” 一般用磁盘的转速 r （单位 转/s）表示，那么
$$
D_r = D_b \times (r \times \pi d_{min}) = r \times f_t
$$
（5）误码率

​		误码率是衡量磁盘出错概率的参数，等于从磁盘读出信息时，出错信息位数和读出信息总位数之比。为了减少出错率，磁盘一般采用循环冗余校验（CRC）码来发现和纠正错误。

##### 5. 冗余磁盘阵列 RAID

​		**冗余磁盘阵列**（Redundant Array of Independent Disks，**RAID**）是将多个独立的物理磁盘组成一个磁盘阵列，引入并行处理技术，让数据在多个物理盘上分割交叉存储、并行访问。 

​		根据不同的目的，可以采用不同的 RAID 方案；在 RAID1 ~ RAID5 的几种方案中，无论何时有磁盘损坏，都可以随时拔出受损的磁盘再插入好的磁盘，而数据不会损坏。RAID 的分级如下所示：

- RAID0：无冗余和无校验的磁盘阵列。

- RAID1：镜像磁盘阵列，无校验。

- RAID2：采用纠错的海明码的磁盘阵列。

- RAID3：位交叉奇偶校验的磁盘阵列。

- RAID4：块交叉奇偶校验的磁盘阵列。
- RAID5：无独立校验的奇偶校验磁盘阵列。

​		其中，RAID0 把连续多个数据块交替地存放在不同物理磁盘的扇区中，几个磁盘交叉并行读写，不仅扩大了存储容量，而且提高了磁盘数据存取速度，但 RAID0 没有容错能力。

​		RAID1 是为了提高可靠性，使两个磁盘同时进行读写，互为备份，如果一个磁盘出现故障，可从另 一磁盘中读出数据。两个磁盘当一个磁盘使用，意味着容量减少一半。

​		总之，RAID通过同时使用多个磁盘，提高了传输率；通过在多个磁盘上并行存取来大幅提高吞吐量；通过镜像功能，提高了安全性、可靠性；通过数据校验，提供容错能力。

#### 3.5.2 固态硬盘（SSD）

​		**固态硬盘**（Solid State Disk，**SSD**）是基于闪存（Flash）技术的半导体存储器，它与 U 盘并没有本质差别。SSD 由闪存芯片和闪存翻译层组成，闪存芯片代替了传统磁盘中的磁盘驱动器，闪存翻译层则将来自 CPU 的读写请求翻译成对芯片的读写控制信号，相当于磁盘中的磁盘控制器。	

![](E:\source\jk-english\英语语法初级\图片\3_40_机械硬盘 vs SSD.png)

​		固态硬盘有很多优点。它由半导体存储器构成，没有机械部件，所以随机访问速度比磁盘快很多，也没有任何机械噪声和震动。另外，SSD 还具有能耗低、抗震性好、安全性高等优点。

​		当然，固态硬盘也有缺点。它最大的问题是依然基于 EEPROM 的擦除原理，随机写入比较慢。

​		固态硬盘的数据都存放在闪存芯片中。一个闪存芯片内包含了多个 “块”，每个块又由若干 “页” 组成。数据以页为单位进行读写，但是需要以块为单位进行擦除；所以只有一页所属的块整个被擦除之后，才能重新写这一页。一旦一个块被擦除了，块中的每一页都可以再写一次。一般某个块进行了数千次重复写之后，就会损坏。

![](E:\source\jk-english\英语语法初级\图片\3_41_SSD结构.png)

​		因此随机写很慢，有两个原因：首先，擦除块本身就比较慢；其次，如果试图写的页所在块已经有数据了，那么这个块中其它所有有数据的页都必须被复制到一个新块（擦除过的块），然后才能进行写操作。

​		因此，闪存的擦写寿命是有限的，读/写数据通常会集中在 SSD 的一部分闪存，这部分闪存就会损坏得特别快；在磨损不均衡的情况下，数个闪存块的损坏，会导致整个 SSD 损坏。为弥补 SSD 的寿命缺陷，引入了 **磨损均衡技术**，SSD 磨损均衡技术大致分为两种：

- 动态磨损均衡：写入数据时，自动选择较新的闪存块。
- 静态磨损均衡：监测并自动进行数据分配，让旧的闪存块承担无须写数据的储存任务，同时让较新的闪存块空出来；平常的读/写操作都在较新的闪存块中进行，这样就使各闪存块的损耗更为均衡。

​		有了磨损均衡技术，SSD 的寿命就比较可观了。例如，对于一个 256 GB 的 SSD，闪存的擦写寿命是 500 次的话，那么就需要写入125 TB 数据才可能损坏；而目前的 Flash 芯片已经做到至少可以擦写上万次了。

### 3.6 高速缓冲存储器（Cache）

​		为了解决 CPU 和主存之间速度不匹配的问题，计算机系统中引入了高速缓存（Cache）的概念。基本想法就是使用速度更快但容量更小、价格更高的 SRAM 制作一个缓冲存储器，用来存放经常用到的信息；这样一来，CPU 就可以直接与 Cache 交换数据，而不用访问主存了。

​		这种方案之所以有效，是因为通过对大量典型程序分析发现，在一定时间内，CPU 要从主存取指令或者数据，只会访问主存局部的地址区域。这是由于指令和数据在内存中都是连续存放的，而且有些指令和数据会被多次调用（比如常用函数、循环代码段、数组和一些常数）；也就是说，指令和数据在主存中地址分布不是随机的，而是相对的簇聚。这使得 CPU 执行程序时，访存具有相对的局部性；这称为程序访问的 **局部性原理**。

- 时间局部性：如果一个数据现在被访问了，那么以后很有可能也会被访问
- 空间局部性：如果一个数据现在被访问了，那么它周围的数据在以后可能也会被访问

​		局部性原理是 Cache 高效工作的理论基础。

#### 3.6.1 Cache 的基本工作原理

​		为了便于 Cache 与主存交换信息，Cache 和主存都被划分为相等的块。Cache 块又称 Cache 行，每块由若干字节组成，块的长度称为块长。由于 Cache 的容量远小于主存的容量，所以 Cache 中的块数要远少于主存中的块数，Cache 中仅保存主存中最活跃的若干块的副本。

##### 1. Cache 工作原理

​		假设主存按字节编址，地址用 n 位二进制码表示，那么主存容量为 2^n^ B；块的大小为 16 个字节，那么主存中块的个数为：2^n^ / 16 = 2^n-4^。那么如果对每个块也做一个编号，其实就对应着地址中的前 n - 4 位。

![](E:\source\jk-english\英语语法初级\图片\3_42_块号和块内地址.png)

​		这样，主存地址就分成了两部分：高 n - 4 位表示主存中的 “块地址”，低 4 位表示 “块内地址”，块内地址其实就是具体存储字在块内的 “偏移量”。类似，Cache 中地址也可以分成这样的两部分，由于 Cache 中块长与主存一致，所以低 4 位同样是块内地址；剩余的高位则为 Cache 的块号。Cache 的块号位数小于 n - 4。

![](E:\source\jk-english\英语语法初级\图片\3_43_块号和块内地址_加标记.png)

​		所以，可按照某种策略预测 CPU 在 未来一段时间内要访存的数据，将其装入 Cache。当 CPU 要读取主存中的某个字时，分为两种情况：

- **Cache 命中**：需要的字已经在缓存中，就将其地址转换为缓存地址，直接访问 Cache，与主存无关；
- **Cache 未命中**：需要的字不在缓存中，仍需访问主存，并将该字所在的块一次性地从主存调入 Cache。

​		如果某个主存块已经调入 Cache，就称该主存块和 Cache 中的缓存块建立了对应关系。由于 Cache 容量有限，当 Cache 已满时，就需要根据某种替换算法，让需要调入 Cache 的块替换之前某个缓存块的内容。所以，一个缓存块不可能永远只对应一个主存块；需要给每个缓存块设置一个标记，写入当前对应的主存块号，表示它当前存放了哪个主存块。

​		CPU 与 Cache 之间的数据交换，通常是以字为单位；而 Cache 与主存之间的数据交换则以块为单位。

##### 2. 命中率

​		Cache 的效率，通常用 **命中率** 来衡量。命中率是指 CPU 要访问的信息已经在 Cache 中的比率。Cache 的容量和块长都是影响命中率的重要因素。

​		假设一个程序执行期间，访问 Cache 的总命中次数为 N~c~，访问主存的总次数为 N~m~，那么命中率为：
$$
h = \frac{N_c}{N_c + N_m}
$$
​		设 t~c~ 为命中时的 Cache 访问时间，t~m~ 为未命中时的主存访问时间，那么 Cache - 主存系统的平均访问时间   t~a~ 为：
$$
t_a = ht_c + (1-h)t_m
$$
​		由于 t~c~ 远小于 t~m~，因此平均访问时间 t~a~ 越接近 t~c~ 就说明 Cache 效率越高。用 e 表示访问效率，则有：
$$
e = \frac {t_c}{t_a} \times 100\% = \frac{t_c}{ht_c + (1-h)t_m} \times 100\%
$$
​		命中率 h 越接近 1，访问效率就高。一般来说，Cache 容量越大，命中率就越高；而块长与命中率的关系较为复杂，它取决于程序的局部特性，一般取每块 4 ~ 8 个可编址单位（字或字节）效果较好。

##### 3. Cache 的基本结构

​		Cache 主要由 Cache 存储体、主存 - Cache 地址映射变换机构、Cache 替换机构几大模块组成。

![](E:\source\jk-english\英语语法初级\图片\3_44_Cache基本结构原理图.png)

​	（1）Cache 存储体

​		Cache 存储体以块为单位与主存交换信息，Cache 访存的优先级最高。

​	（2）主存 - Cache 地址映射变换机构

​		地址映射变换机构会将 CPU 送来的主存地址转换为 Cache 地址。由于主存和 Cache 块长相同，所以块内地址是不变的，地址变换主要就是主存的块号（高位地址）到 Cache 块号之间的转换。这涉及到一个函数的映射关系，被称为 **地址映射**。

​	（3）Cache 替换机构

​		地址转化之后，如果 Cache 命中，CPU 就直接访问 Cache 存储体；如果不命中，CPU 需要访问主存将需要的字取出，并把它所在的主存块调入 Cache。如果 Cache 已满，无法将主存块直接调入 Cache，就需要 Cache 内的替换机构执行替换策略。

​		所谓替换策略，就是按一定的替换算法，确定从 Cache 中移出哪个块返回主存，并把新的主存块调入 Cache 进行替换。

​		在执行写操作时，还需要考虑如何使 Cache 如何与主存的内容保持一致。这就需要用某种 Cache 写策略。

##### 4. Cache 的改进

​		Cache 的改进，主要就是由一个缓存改为使用多个缓存。主要有两个方向：增加 Cache 级数；将统一的 Cache 变为分立的 Cache。

​	（1）两级缓存

​		最初在 CPU 和主存之间只设一个缓存，称为 **单一缓存**。随着集成电路密度的提高，这个缓存就直接与 CPU 集成在了一个芯片中，所以又称为 **片内缓存（片载缓存）**。

​		由于片内缓存容量无法做到很大，所以可以考虑在片内缓存和主存之间再加一级缓存，称为 **片外缓存**，也由 SRAM 组成。这种由片外缓存和片内缓存构成的 Cache 系统被称为 “**两级缓存**”，片内缓存作为第一级（L1 Cache），片外缓存作为第二级（L2 Cache）。

​	（2）分立缓存

​		指令和数据都存放在同一缓存内的 Cache，称为 **统一缓存**；而 **分立缓存** 则将指令和数据分别存放在两个缓存中，一个叫指令 Cache，另一个叫数据 Cache。这两种缓存的选择主要考虑两个因素：

- 主存结构。如果计算机主存中指令、数据是统一存储的，则相应的 Cache 采用统一缓存；如果主存指令、数据分开存储，则相应的 Cache 采用分立缓存。
- 机器对指令执行的控制方式。如果采用了超前控制或者流水线控制方式，一般都采用分立缓存。所谓超前控制，是指在当前指令执行尚未结束时就提前把下一条准备执行的指令取出；而所谓流水线控制，就是多条指令同时分阶段执行。

#### 3.6.2 Cache 和主存之间的映射方式

​		Cache 块中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到 Cache 地址空间，这相当于定义了一个函数：

​																	Cache 地址 = *f* ( 主存地址 )

​		当然，由于 Cache 和主存块长一样，而块内地址只是字在当前块内的 “偏移量”，所以映射转换之后块内地址是不变的。我们需要的其实只是 Cache 块号和主存块号之间的函数关系：

​																	Cache 块号 = *f* ( 主存块号 )

​		Cache 块远少于主存块，所以 Cache 块不可能永远对应唯一的主存块，需要在 Cache 中为每一个块加一个 **标记**，指明它是主存中哪一块的副本。这个标记的内容，应该能够唯一确定对应主存块的编号。另外，为了说明 Cache 行中的信息是否有效，每个 Cache 行还需要有一个 **有效位**，该位为 1 时，表示 Cache 中该映射的主存块数据有效；为 0 则无效。

​		地址映射的方法有以下 3 种。

##### 1. 直接映射

​		**直接映射 **的思路非常简单，就是 “挨个对应”，主存中的每一块只能装入 Cache 中的唯一位置。由于 Cache 容量很小，当主存中的块已经 “遍历” 完所有 Cache 地址后，下一个主存块的对应位置就又成了 Cache 中的第一行（第一个块）。

​		很明显，这跟 “顺序存储” 的思路是一样的，用主存块号对 Cache 的总行数取模，就可以得到对应 Cache 的行号了：

​																Cache行号 = 主存块号  ***mod***  Cache总行数

​		例如，假设主存地址为 32 位，按字节编址，主存块大小为 64 B，所以主存块共有 2^32^ / 64 = 2^26^ 个；如果 Cache 只有 4 行（4 个块），那么采用直接映射方式的对应关系如下：

![](E:\source\jk-english\英语语法初级\图片\3_45_直接映射.png)

​		更加一般化，假设 Cache 共有 2^c^ 行，主存有 2^m^ 个块，那么 Cache 行号有 c 位，主存块号有 m 位。在直接映射方式中，主存块号为 0、2^c^、2^c+1^... 的块，都映射到 Cache 的第 0 行；而主存中块号为 1、2^c^ + 1、2^c+1^ + 1... 的块，映射到 Cache 的第 1 行；以此类推。

​		这样一来，主存块号的低 c 位就对应了 Cache 中的行号；当一个块存放在 Cache 中，只需要高 m - c 位就可以指明它对应的主存中的块号。给每个 Cache 行设置一个 **t = m - c** 位的标记，那么当主存某块调入 Cache 后，就将其块号的高 t 位设置在对应 Cache 行的标记中。

​		所以直接映射方式下，主存地址结构为：

![](E:\source\jk-english\英语语法初级\图片\3_46_直接映射地址结构.png)

​		访存过程：

​		① 根据访存地址中间的 c 位，找到对应的 Cache 行。

​		② 将该 Cache 行中的标记和主存地址的高 t 位标记进行比较。

​		③ 若相等且有效位为1，则 Cache 命中，此时根据主存地址中低位的块内地址，在对应的 Cache 行中存取信息；若不相等或有效位为 0，则 Cache 未命中，此时 CPU 从主存中读出该地址所在的一块信息，并送至对应的 Cache 行中，将有效位置 1，并置标记为地址中的高 t 位。

![](E:\source\jk-english\英语语法初级\图片\3_47_访存过程.png)

​		直接映射实现简单，但不够灵活，即使 Cache 的其他许多地址空着也不能占用，这使得直接映射的块冲突概率高，空间利用率低。

##### 2. 全相联映射

​		直接映射的问题在于，我们找到的是从主存块到缓存行的一种 “多对一” 的关系，每一个主存块只能对应唯一的缓存行，从而导致冲突概率高。如果让一个主存块，可以映射到多个缓存块上，变成 “多对多” 的关系，明显就可以减少冲突了。

​		最简单的情况，就是不加任何条件限制，让主存的每一个块都可以映射到 Cache 的任意位置；简单来说就是 “有空就填”，放在哪里都可以。这就是 **全相联映射** 方式。

![](E:\source\jk-english\英语语法初级\图片\3_48_全相联映射.png)

​		由于没有任何规律，所以当一个块存放在 Cache 中，无法根据 Cache 行号推出它对应主存块的任何信息；因此必须在每行的标记中明确指出该行取自主存的哪一块，这样标记就需要完整的 m 位主存块号。CPU 访存时，需要与所有 Cache 行的标记进行比较。

​		全相联映射方式下，主存的地址结构为：

![](E:\source\jk-english\英语语法初级\图片\3_49_全相联映射地址结构.png)

​		全相联映射方式的优点是灵活，Cache块的冲突概率低，空间利用率高，命中率也高；缺点是标记的速度较慢，实现成本较高，通常需采用昂贵的按内容寻址的相联存储器进行地址映射。

##### 3. 组相联映射

​		把直接映射和全相联映射两种方式结合起来，就是 **组相联映射** 方式。

​		组相联的思路是将 Cache 分成 Q 个大小相等的组，每个主存块可装入对应组的任意一行；它所在的组则按顺序依次排列得到。也就是 **组间采用直接映射**、而 **组内采用全相联映射** 的方式。当 Q=1 时，变为全相联映射；当 Q = Cache 行数时变为直接映射。

​		假设每组有 R 个 Cache 行，则称之为 R 路组相联；例如每组有 2 个 Cache 行时称为 2 路组相联。

​		类似的例子，假设主存地址为 32 位，按字节编址，主存块大小为 64 B，所以主存块共有 2^32^ / 64 = 2^26^ 个；如果 Cache 有 8 行（8 个块），采用 2 路组相联映射方式，那么共有 Q = 8 / 2 = 4 组。对应关系如下：

![](E:\source\jk-english\英语语法初级\图片\3_50_组相联映射.png)

​		可以看出，现在的 “组号” 就相当于直接映射方式下的行号，可以由主存块号对组数 Q 取模得到：

​														Cache组号 = 主存块号  ***mod***  Cache组数

​		更加一般化，假设 Cache 共有 2^c^ 行，分为 Q = 2^q^ 组，主存有 2^m^ 个块；那么 Cache 行号有 c 位，其中高 q 位是组号，主存块号有 m 位。这时每组中的 Cache 行数为 R = 2^c^ / Q = 2^c-q^ ，行号的低 c - q 位就代表了 Cache 行在组内的序号。

​		在 R 路组相联映射方式中，主存块号为 0、2^q^、2^q+1^... 的块，都映射到 Cache 的第 0 组，可以选择组内 2^c-q^ 行的任一行；而主存中块号为 1、2^q^ + 1、2^q+1^ + 1... 的块，映射到 Cache 的第 1 组，同样可以任选组内的 Cache 行；以此类推。

​		这样一来，主存块号的低 q 位就对应了 Cache 中的组号；当一个块存放在 Cache 中，只需要高 m - q 位就可以指明它对应的主存中的块号。给每个 Cache 行设置一个 **t = m - q** 位的标记，那么当主存某块调入 Cache 后，就将其块号的高 t 位设置在对应 Cache 行的标记中。

​		所以组相联映射方式下，主存地址结构为：

![](E:\source\jk-english\英语语法初级\图片\3_51_组相联映射地址结构.png)

​		访存过程：

​		① 先根据访存地址中间的 Cache 组号，找到对应的 Cache 组。

​		② 然后将该组中每个 Cache 行的标记与主存地址的高位标记进行比较。

​		③ 若有一个相等且有效位为1，则 Cache 命中，此时根据主存地址中的块内地址，在对应 Cache 行中存取信息；若都不相等，或虽相等但有效位为 0，则 Cache 未命中，此时 CPU 从主存中读出该地址所在的一块信息，并送至对应 Cache 组的任意一个空闲行，将有效位置 1，并设置标记。

​		组相联映射方式下，路数 R 越大，即每组 Cache 行的数量越多，发生块冲突的概率越低，但比较电路也越复杂。

​		可以将以上 3 中映射方式对比如下：

![](E:\source\jk-english\英语语法初级\图片\3_52_三种映射方式对比.png)

#### 3.6.3 Cache 中主存块的替换算法

​		如果有新的主存块需要调入 Cache，而可用空间又已经占满，这时就需要替换掉某个旧块，这就产生了替换策略（替换算法）的问题。当采用直接映射时，替换的位置是固定的，无须考虑替换算法；而在采用全相联映射或组相联映射时，就需要使用替换算法来确定到底置换哪个 Cache 行。

​		常用的替换算法有 **随机（RAND）算法**、**先进先出（FIFO）算法**、**最近最少使用（LRU）算法** 和 **最不经常使用（LFU）算法**。其中最常考查的是 LRU 算法。

- 随机算法：随机地确定替换的 Cache 块。实现简单，但未依据局部性原理，命中率较低。
- 先进先出算法（Fisrt In First Out，FIFO）：选择最早调入的行进行替换。实现简单，但也未依据局部性原理。
- **最近最少使用算法（Least Recently Used，LRU）**：依据局部性原理，选择近期最久未访问过的 Cache 行作为被替换的行。LRU 算法为每个 Cache 行设置一个**计数器**，用来记录每个块的使用情况，并根据计数值选择淘汰某个块。
- 最不经常使用算法（Least Frequently Used，LFU）：将一段时间内访问次数最少的 Cache 行换出。与 LRU 类似，也设置一个计数器，Cache 行建立后从 0 开始计数，每访问一次计数器加 1，需要替换时将计数值最小的行换出。

​		例如，假设一台机器 Cache 有 8 个行，初始值为空，采用 4 路组相联映射方式和 LRU 替换策略，当顺序访问主存块号为 0，4，8，3，0，6，12，0，4，8 时，缓存的命中和替换情况如下：

![](E:\source\jk-english\英语语法初级\图片\3_53_LRU替换策略示例.png)

​		LRU 算法中利用计数器来表示 Cache 行未被访问的时间。整体原则是：当 Cache 行有新的主存块调入时，计数器开始计数，初始值为 0，此后每遇到一次对 Cache（或 Cache 组）的访问就加 1；如果一次访问 Cache 命中了这一行，就将计数器清 0；每次有 Cache 行计数器清 0，其它行的计数器依然要加 1，不过只需要计数值比当前行更小的那些继续加 1 就可以了。

​		需要替换时，直接选择计数值最大的行，调入新的块并将计数器置 0。这是由于不同的 Cache 行不会同时开始计数，且每次都同步加 1，所以所有 Cache 行的计数值都不会相同，每次发生替换时必然能够找到一个最大值；而一旦有计数器清 0，比它计数值更大的那些也是都不加 1，依然保持着原有的大小顺序。

​		这样一来，如果当前 Cache 共有 2^c^ 行，分为 Q = 2^q^ 组，每组行数为 R = 2^c^ / Q = 2^c-q^ ，那么计数器的值就不会超过 R；只要用 c - q 位就可以表示计数器了，这被叫做 **LRU 位**。因此，计数值的位数与 Cache 组的大小有关。当为 2 路时有 1 位 LRU 位，4 路时有 2 位 LRU 位。LRU 位会同标记、有效位一同作为 Cache 的一部分。


#### 3.6.4 Cache 写策略

​		因为 Cache 中的内容是主存块内容的副本，当对 Cache 中的内容进行更新时，就需选用写操作策略使 Cache内容和主存内容保持一致。此时分两种情况：

（1）Cache 写命中（要修改的单元在 Cache 中）

​		这种情况有两种处理方法：

- 写直达法


​		也叫全写法、写穿透法。将数据同时写入 Cache 和主存。这种方法实现简单，一致性好。缺点是降低了速度，时间开销为访存时间。为了减少写入主存的开销，可以在 Cache 和主存之间加一个写缓冲。

- 写回法


​		也叫回写法、写返回法。数据只写入 Cache，而不立即写入主存，只有当此块被换出时才写回主存。这种方法效率很高，但一致性较差。在每个 Cache 行中设置一个修改位（脏位），若修改位为 1（“脏”），则说明对应 Cache 行中的块被修改过，替换时须写回主存；若修改位为 0（“净”），则替换时无须写回主存。

（2） Cache 写未命中（要修改的单元不在 Cache中 ）

​		这种情况也有两种处理方法：

- 写分配法

​		把数据写入主存，同时将该块调入Cache。这种方法依据了空间局部性原理。

- 非写分配法

​		只把数据写入主存，不进行调块。

​		非写分配法通常与全写法合用，写分配法通常与回写法合用。

​		这样，还是之前的机器，采用组相联映射的 Cache 共有 2^c^ 行，分为 Q = 2^q^ 组，主存有 2^m^ 个块；那么 Cache 行号有 c 位，其中高 q 位是组号，主存块号有 m 位。这时每组中的 Cache 行数为 R = 2^c^ / Q = 2^c-q^  ，即采用 R 路组相联映射，假如还采用了 LRU 替换策略和回写法，那 Cache 行应该包含以下部分：

![](E:\source\jk-english\英语语法初级\图片\3_54_有LRU位的Cache行.png)

​		现代计算机通常设立多级 Cache，一般两级 Cache 按离 CPU 的远近分别命名为 L1 Cache、L2 Cache，离 CPU 越近则速度越快、容量越小。指令 Cache 与数据 Cache 分离一般在 L1 级，LI Cache 对 L2 Cache 使用全写法，L2 Cache 对主存使用回写法。由于L2 Cache的存在，避免了因频繁写而造成写缓冲溢出的情况。

### 3.7 虚拟存储器

​		早期的计算机，CPU 是直接操作主存的，也就是运行程序时，直接给出要访问的实际主存地址。这种方式简单直接，但是会有一些问题：

- 不同的程序之间需要共享内存，它们的内存地址空间很难隔离，从而导致程序运行的稳定性和安全性降低；
- 主存容量有限，如果同时执行的程序太多、使用内存太大容易超出容量限制而崩溃。

​								<img src="C:/Users/18133/Desktop/课件/pictures/3_55_多个程序对内存的争用.png" style="zoom:75%;" />

​		为了解决这些问题，在主存-辅存这一层次的不断发展中，逐渐形成了虚拟存储系统。

​		主存和辅存共同构成了虚拟存储器，二者在硬件和系统软件的共同管理下工作。对于应用程序员而言，虚拟存储器是透明的。虚拟存储器具有主存的速度和辅存的容量。

#### 3.7.1 虚拟存储器的基本概念

​		虚拟存储器将主存和辅存的地址空间统一编址，形成一个庞大的地址空间，在这个空间内，用户可以自由编程，而不必在乎实际的主存容量和程序在主存的实际存放位置。用户编程允许涉及的地址称为 **虚地址** 或 **逻辑地址**，虚地址对应的存储空间称为虚拟空间。实际的主存地址称为 **实地址** 或 **物理地址**，实地址对应的是主存地址空间。虚地址比实地址要大很多。

​		使用虚拟存储器之后，程序中看到的地址都是逻辑地址。在访存时，逻辑地址首先会被转换成物理地址，然后再访问实际物理内存。

![](E:\source\jk-english\英语语法初级\图片\3_56_物理地址和虚拟地址的转换.png)

​		这样一来，每一个程序都有独立的虚拟地址空间，不同进程的虚拟地址空间互相不干扰，提高了安全性。在每个进程看来，就像它自己独享了整个内存。当物理内存不够时，可以将一部分不常使用的内存块换出（Swap-out）到磁盘中，下次使用时再换入到内存中（Swap-in），这样程序就可以使用超过实际物理内存大小的地址空间了。

![](E:\source\jk-english\英语语法初级\图片\3_57_虚拟存储器中多个程序对内存的共享.png)

​		CPU 使用逻辑地址时，先判断这个逻辑地址对应的内容是否已装入主存。若已在主存中，则通过地址变换，CPU 可直接访问主存指示的实际单元；若不在主存中，则把包含这个字的一页或一段调入主存后再由 CPU 访问。若主存已满，则采用 **替换算法** 置换主存中的页。

​		虚拟存储器采用了和 **Cache** 类似的技术，将辅存中经常被访问的数据副本存放到主存中。但缺页 （或段）而访问辅存的代价很大，因此虚存机制采用 **全相联映射**，每个页可以存放到主存区域的任意一个空闲页位置。此外，当进行写操作时，不能每次写操作都同时写回磁盘，因而采用 **回写法**。	

#### 3.7.2 页式虚拟存储器

​		**页式虚拟存储器** 以页为基本单位。虚拟空间与主存空间都被划分成同样大小的页，主存的页称为 **实页** 或 **页框**，虚存的页称为 **虚页**。这样，一个逻辑地址可以分为两段：**虚页号** 和 **页内地址**。

![](E:\source\jk-english\英语语法初级\图片\3_58_逻辑地址结构.png)

​		虚页和实页之间采用全相联映射，所以从主存中依次查找要访问的虚页号比较困难。所以我们专门引入一个数据结构，用来保存虚页号和实页号的映射关系，这就是 **页表**。页表可以实现从逻辑地址到物理地址的转换。

##### 1. 页表

​		页表是一张存放在主存中的虚页号和实页号的对照表，它记录程序的虚页调入主存时被安排在主存中的位置。每个程序都有自己的页表，页表一般长久地保存在内存中。

​		页表中的每一项，都包含以下几部分：

- **有效位**：也称 **装入位**，用来表示对应页面是否在主存，若为 1，则表示该虚页已从外存调入主存，此时页表项存放该页的物理页号；若为 0，则表示页面没有调入主存，此时页表项可以存放该页的磁盘地址。
- **脏位**：也称 **修改位**，用来表示页面是否被修改过，虚拟存储机制中采用回写策略，利用脏位可判断替换时是否需要写回磁盘。
- **引用位**：也称 **使用位**，用来配合替换策略进行设置，例如是否使用先进先出（FIFO）或近期最少使用（LRU）策略等。

![](E:\source\jk-english\英语语法初级\图片\3_59_页表.png)

​		CPU 执行指令时，需要先将逻辑地址转换为主存物理地址。每个进程都有一个 **页表基址寄存器**，存放该进程的页表首地址，然后根据逻辑地址高位部分的虚页号找到对应的页表项。若装入位为 1，则取出物理页号，和逻辑地址低位部分的页内地址拼接，形成物理地址；若装入位为 0，则说明缺页，需要操作系统进行 **缺页处理**。缺页时会由 CPU 的内存管理单元（MMU）发出中断，操作系统需要将相应的页从磁盘取回调入主存，并将物理页的地址填入页表中。

​		页式虚拟存储器的优点是：页的长度固定，页表简单，调入方便。缺点是：最后一页的零头无法利用而造成浪费，并且页不是逻辑上独立的实体，所以处理、保护和共享都不及段式虚拟存储器方便。

##### 2. 快表（TLB）

​		有了虚拟存储器之后，CPU 在寻址时所生成的都是虚拟地址。于是 CPU 在取指或者执行访存指令的时候，都需要进行地址翻译，而每次地址翻译都要访问主存中的页表，会产生严重的开销。

​		依据程序执行的局部性原理，当 CPU 在一段时间内总是经常访问某些页时，若把这些页对应的页表项存放在 Cache 中，就可以不访问主存直接进行地址翻译了；这样明显能提高效率。

​		在 CPU 芯片中，加入一个专门存放最常访问的页表项的 Cache，就叫做 **转址旁路缓存**（Translation Lookaside Buffer，**TLB**），一般简称为 “**快表**”。TLB 实质上就是 “页表的 Cache”，其中存储了当前最可能被访问到的页表项，其内容是部分页表项的一个副本；所以 TLB 又被称为 **页表缓存**。

![](E:\source\jk-english\英语语法初级\图片\3_60_多级缓存关系.png)

​		相应地，把放在主存中的页表称为 **慢表（Page）**。 在地址转换时，先查找快表，若命中，则无须再访问主存中的页表（慢表）。

​		TLB 通常采用 **全相联映射**。每个 TLB 项由页表表项内容加上一个 TLB 标记字段以及有效位等标志位组成，TLB 标记用来表示该表项取自页表中哪个虚页号对应的页表项，其内容就是该页表项对应的虚页号。

![](E:\source\jk-english\英语语法初级\图片\3_61_TLB项.png)

##### 3. 具有 TLB 和 Cache 的多级存储系统

​		TLB 和 Cache 都属于缓存，不过它们的用途不同：

- TLB 用来保存最近经常访问的页表项，是对 **地址映射** 的缓存。
- Cache 用来保存最近经常访问的主存块，是对 **数据内容** 的缓存。

​		所以对于一个有虚拟存储器的计算机系统，可以先通过 TLB 对逻辑地址的翻译进行加速，快速得到一个物理地址；然后再通过 Cache 的地址转换判断是否 Cache 命中，从而对数据的访问进行加速。

​		这样就将 Cache 和 TLB 结合起来，构成了多级存储系统。下面就是一个具有 2 路组相联映射 Cache 和 TLB 的多级存储系统；CPU 给出的是一个 32 位的逻辑地址，TLB 采用全相联映射，每一项都有一个比较器。

![](E:\source\jk-english\英语语法初级\图片\3_62_有TLB和Cache的多级存储系统.png)

- 查找时将虚页号与每个 TLB 标记同时进行比较，若有某一项相等且对应有效位为 1，则 TLB 命中，此时可直接通过TLB进行地址转换；若未命中，则 TLB 缺失，需要访问主存去査页表。
- 图中所示是 **两级页表方式**，虚页号被分成 **页目录索引** 和 **页表索引** 两部分，由这两部分得到对应的页表项，从而进行地址转换，并将相应表项调入TLB。若 TLB 已满，则还需要采用替换策略。
- 完成由逻辑地址到物理地址的转换后，Cache 机构根据映射方式将物理地址划分成多个字段，然后根据映射规则找到对应的 Cache 行或组，将对应 Cache 行中的标记与物理地址中的高位部分进行比较，若相等且对应有效位为1，则 Cache 命中，此时根据块内地址取岀对应的字送 CPU。

​		查找时，快表和慢表也可以同步进行。若快表中有此虚页号，则能很快地找到对应的实页号，并使慢表的查找作废，从而就能做到虽采用虚拟存储器，但访问主存速度几乎没有下降。

​		在一个具有 Cache 和 TLB 的虚拟存储系统中，CPU —次访存操作可能涉及对 TLB、页表（Page）、Cache、主存和磁盘的访问。CPU 在访存过程中存在 3 种缺失情况：

​		① TLB 缺失：要访问页面的页表项不在 TLB 中；

​		② Page 缺失：要访问的页面不在主存中。

​		③ Cache 缺失：要访问的主存块不在 Cache 中；

​		需要注意，如果 TLB 命中，那么 Page 一定命中；如果 Page 缺失，那么 Cache 一定缺失。所以有如下一些组合情况：

![](E:\source\jk-english\英语语法初级\图片\3_63_TLB、Page、Cache命中情况组合.png)

- 第 1 种情况下，无须访问主存，地址转换和访问数据都可以通过高速缓存完成；
- 第 2 种和第 3 种情况都 需要访问一次主存，第 2 种是访问主存取数据，第 3 种是访问页表转换物理地址；
- 第 4 种情况需要访问两次主存，访问页表转换物理地址一次、访存取数据一次；
- 第 5 种情况就是 “缺页异常”，需要访问磁盘，并且至少访问两次主存。

​		Cache 缺失处理由硬件完成；缺页处理由软件完成，操作系统通过 “缺页异常处理程序” 实现；而 TLB 缺失既可以用硬件也可以用软件来处理。

#### 3.7.3 段式虚拟存储器

​		在段式虚拟存储器中，将虚拟空间用 “**段**” 进行分割；而段是按程序的逻辑结构划分的，各段的长度因程序而异。虚地址分为两部分：**段号** 和 **段内地址**。虚地址到实地址之间的变换是由 **段表** 来实现的。段表的每行记录与某个段对应的段号、 装入位和段长等信息。由于段的长度可变，所以段表中要给出各段的起始地址与段的长度。

​		![](E:\source\jk-english\英语语法初级\图片\3_64_段式虚拟存储器.png)

​		CPU 用逻辑地址访存时，先根据段号与段表基地址拼接成对应的段表项，再根据该段表项的装入位判断该段是否已调入主存（装入位为 “1”，表示该段已调入主存）。当已调入主存时，从段表读岀该段在主存的起始地址，与段内地址相加，得到对应的主存物理地址。

​		段式虚拟存储器的优点是，段的分界与程序的逻辑分界相对应，这使得程序易于编译、修改和保护，也便于多道程序共享；缺点是因为段长度可变，分配空间不便，容易留下碎片，造成浪费。

#### 3.7.4 段页式虚拟存储器

​		把程序按逻辑块分段，段内再分页，主存空间也划分为大小相等的页，程序对主存的调入调出仍以 **页** 为基本单位，这样的虚拟存储器称为 **段页式虚拟存储器**。在段页式虚拟存储器中，每个程序对应一个 **段表**，每段对应一个 **页表**，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。

![](E:\source\jk-english\英语语法初级\图片\3_65_段页式逻辑地址结构.png)

​		虚地址分为 **段号**、**段内页号**、**页内地址** 3 部分。CPU 根据虚地址访存时，首先根据段号得到段表地址，然后从段表中取出该段的页表起始地址，与虚地址段内页号拼接，得到页表地址；最后从页表中取出实页号，与页内地址拼接成主存实地址。

​		段页式虚拟存储器的优点是，兼具页式和段式虚拟存储器的优点，可以按段实现共享和保护；缺点是在地址变换过程中需要两次查表，系统开销较大。

#### 3.7.5 虚拟存储器与 **Cache** 的比较

​		相同点：

- 目标都是为了提高系统性能，两者都有容量、速度、价格的梯度。
- 都把数据划分为信息块，作为基本的传送单位，虚拟存储器系统的信息块更大。
- 都有地址的映射算法、替换算法、更新策略等问题。
- 依据局部性原理，应用“快速缓存”思想，将活跃的数据放在相对高速的部件中。

​		不同点：

- Cache主要是为了提高系统速度，而虚拟存储器是为了解决主存容量不足的问题。
- Cache由硬件实现，对所有程序员透明；虚拟存储器由操作系统和硬件共同实现，对应用程序员透明。
- 在不命中时对性能的影响不同。因为 CPU 的速度约为 Cache 的 10 倍，而主存的速度为硬盘的 100 倍以上，因此虚拟存储器系统在不命中时对系统性能的影响更大。
- CPU 与 Cache 和主存有直接通路，而辅存与 CPU 没有直接通路。在 Cache 不命中时，CPU 能和主存直接通信；而虚拟存储器系统在不命中时，须先将数据从硬盘调入主存，CPU 才能访问。

### 3.8 章节练习

#### 一、单项选择题

1. 【2010真题】下列有关 RAM 和 ROM 的叙述中，正确的是	（    ）。

​		Ⅰ ． RAM 是易失性存储器， ROM 是非易失性存储器
​		Ⅱ ． RAM 和 ROM 都采用随机存取方式进行信息访问
​		Ⅲ． RAM 和 ROM 都可用作 Cache
​		Ⅳ． RAM 和 ROM 都需要进行刷新

​		A．仅Ⅰ 和Ⅱ 					B．仅Ⅱ 和Ⅲ					C．仅Ⅰ 、 Ⅱ 和Ⅳ 					D．仅Ⅱ 、 Ⅲ和Ⅳ

​		答案：A

2. 【2011真题】下列各类存储器中，不采用随机存取方式的是    （    ）。

​		A． EPROM   					B． CDROM   					C． DRAM   						D． SRAM

​		答案：B

3. 【2015真题】下列存储器中，在工作期间需要周期性刷新的是	（    ）。		

​		A． SRAM   	 				B． SDRAM							C． ROM	     				D． FLASH 

​		答案：B

4. 【2012真题】下列关于闪存（Flash Memory）的叙述中，错误的是 	（    ）。

​		A． 信息可读可写，并且读、写速度一样快

​		B． 存储元由 MOS 管组成，是一种半导体存储器

​		C． 掉电后信息不丢失，是一种非易失性存储器

​		D． 采用随机访问方式，可替代计算机外部存储器 

​		答案：A

5. 【2011真题】某计算机存储器按字节编址，主存地址空间大小为 64MB，现用 4MB×8 位的 RAM
   芯片组成 32MB 的主存储器，则存储器地址寄存器 MAR 的位数至少是 	（    ）。

​		A． 22 位   					B． 23 位   					C． 25 位   					D． 26 位

​		答案：D

​		要点：MAR 的位数跟主存地址空间有关，与主存实际容量无关。

6. 【2010真题】假定用若干个 2K×4 位的芯片组成一个 8K×8 位的存储器，则地址 0B1FH 所在芯片
   的最小地址是	（   ）。

​		A． 0000H 					B． 0600H 					C． 0700H 					D． 0800H

​		答案：D

7. 【2014真题】某容量为 256MB 的存储器由若干 4Mx8 位的 DRAM 芯片构成， 该 DRAM 芯片的地址引脚和数据引脚总数是	（    ） 。

​		A. 19 							B. 22 						C. 30 						D. 36 

​		答案：A		

​		要点：DRAM 采用地址复用技术，地址线为正常的一半。 

8. 【2016真题】某存储器容量为 64KB，按字节编址，地址 4000H~5FFFH 为 ROM 区，其余为 RAM 区。若采用 8K× 4 位的 SRAM 芯片进行设计，则需要该芯片的数量是 	（    ）。

​		A． 7 							B． 8  						C． 14 						D． 16 

​		答案：C

9. 【2018真题】假定 DRAM 芯片中存储阵列的行数为 r、列数为 c，对于一个2Kx1 位的 DRAM 芯片，为保证其地址引脚数最少，并尽量减少刷新开销，则 r、c的取值分别是	（    ）。

​		A. 2048、1					B. 64、32					C. 32、64					D. 1、2048

​		答案：C

​		要点：DRAM 芯片采用地址复用技术，按行刷新。

10. 【2017真题】某计算机主存按字节编址，由 4 个 64M × 8 位的 DRAM 芯片采用交叉编址方式构成，并与
    宽度为 32 位的存储器总线相连，主存每次最多读写 32 位数据。若 double 型变量 x 的主存地址为 804 001AH，则读取 x 需要的存储周期数是	（    ）。

​		A． 1 							B． 2	 						C． 3 							D． 4 

​		答案：C

​		要点：多体低位交叉存储器可增大带宽，每个存储周期对所有芯片各读取一次；double 型变量占 8 个字节。

11. 【2021真题】某计算机的存储器总线中有 24 位地址线和 32 位数据线，按字编址，字长为 32 位。若 00 0000H~3F FFFFH 为 RAM 区，则需要 512K x 8 位的 RAM 芯片数为	（    ）。

​		A.8								B.16								C.32								D.64

​		答案：C

12. 【2022真题】某内存条包含 8 个 8192 x 8192 x 8 位的 DRAM 芯片，按字节编址，支持突发 (burst) 传送方式，对应存储器总线宽度为 64 位，每个 DRAM 芯片内有一个行缓冲区 (row buﬀer)。 下列关于该内存条的叙述中，不正确的是	（   ）。

​		A. 内存条的容量为 512 M 							B. 采用多模块交叉编址方式

​		C. 芯片的地址引脚为 26 位 						  D. 芯片内行缓冲有 8192 x 8 位 

​		答案：C

​		要点：DRAM 芯片采用地址复用技术，地址引脚为正常的一半；行缓冲区的大小就是一行的大小。

13. 【2013真题】下列选项中，用于提高 RAID 可靠性的措施有	（    ）。

​		I.磁盘镜像		II. 条带化		III.奇偶校验		IV.增加 Cache机制

​		A.仅I、II			B.仅I、III			C.仅I、III和IV			D.仅II、III和IV

​		答案：B

​		要点：RAID 通过条带化来实现并行读写；通过磁盘镜像和校验增加可靠性。

14. 【2013真题】某磁盘的转速为 10000 转/分，平均寻道时间是 6ms，磁盘传输速率是 20MB/s，磁盘控
    制器延迟为 0.2ms，读取一个 4KB 的扇区所需的平均时间约为	（    ）。

​		A.9ms					B.9.4 ms					C.12 ms					D. 12.4 ms

​		答案：B

​		要点：平均访问时间 =  平均寻道时间 + 平均等待时间 + 数据传输时间 + 控制器延迟  。

15. 【2015真题】若磁盘转速为 7200 转/分，平均寻道时间为 8 ms，每个磁道包含 1000 个扇区，则访问一个扇区的平均存取时间大约是 	（    ）。

​		A． 8.1 ms 					B． 12.2 ms 				C． 16.3 ms 					D． 20.5 ms

​		答案： B

​		要点：平均访问时间 =  平均寻道时间 + 平均等待时间 + 数据传输时间  。

16. 【2019真题】下列关于磁盘存储器的叙述中，错误的是 	（    ）。

​		A．磁盘的格式化容量比非格式化容量小				B．扇区中包含数据、地址和校验等信息

​		C．磁盘存储器的最小读写单位为一字节				D．磁盘存储器由磁盘控制器、磁盘驱动器和盘片组成 

​		答案：C

​		要点：磁盘最小读写单位为一个扇区。

17. 【2014真题】采用指令 Cache 与数据 Cache 分离的主要目的是	（    ） 。

​		A. 降低 Cache 的缺失损失				 B. 提高 Cache 的命中率				

​		C. 降低 CPU 平均访存时间 				D. 减少指令流水线资源冲突

​		答案：D

18. 【2017真题】某C语言程序段如下：

```C
for(i=0; i<=9; i++)
{ 
    temp=1;
    for(j=0； j<=i； j++)temp * =a[j];
    sum + =temp；
}
```

​		下列关于数组 a 的访问局部性的描述中，正确的是 	（    ）。

​		A．时间局部性和空间局部性皆有

​		B．无时间局部性，有空间局部性

​		C．有时间局部性，无空间局部性

​		D．时间局部性和空间局部性皆无 

​		答案：A

19. 【2015真题】假定主存地址为 32 位，按字节编址，主存和 Cache 之间采用直接映射方式，主存块大小为 4 个字，每字 32 位，采用回写（Write Back）方式，则能存放 4K 字数据的 Cache 的总容量的位数至少是 		（    ）。

​		A． 146K 							B． 147K						C． 148K 						D． 158K

​		答案：C

​		要点：直接映射方式下，主存块号位数 m = 标记位数 t + Cache 行号位数 c ；

​					回写策略下，每个 Cache 行需要另加 1 位修改位（脏位）；

​					Cache 行总位数 = 1位有效位 + 1位修改位 +（LRU位）+ 标记 + 数据。

20. 【2022真题】若计算机主存地址为 32 位，按字节编址，某 Cache 的数据区容量为 32KB, 主存块大小为 64B, 采用 8 路组相联映射方式，该 Cache 中比较器的个数和位数分别为 	（    ）。

​		A. 8, 20 					B. 8, 23 					C. 64, 20 					D. 64, 23 

​		答案：A

​		要点：Cache 中比较器的个数就是组相联的路数 R，比较器的位数就是标记 t 的位数。

​					组相联映射方式下，主存块号位数 m = 标记位数 t + Cache 组号位数 q

21. 【2016真题】有如下 C 语言程序段：

```c
for(k=0; k<1000; k++)
    a[k] = a[k]+32;
```

​		若数组 a 及变量 k 均为 int 型， int 型数据占 4B，数据 Cache 采用直接映射方式，数据区大小为 1KB、块大小为 16B，该程序段执行前 Cache 为空，则该程序段执行过程中访问数组 a 的 Cache 缺失率约为 	（    ）。

​		A． 1.25% 					B． 2.5% 					C． 12.5% 					D． 25% 

​		答案：C

​		要点：循环内语句需要对 a[k] 访问两次，第一次未命中，并将其所在块调入主存；第二次命中；在该块中的后面三个元素的 6 次访问也都命中。

22. 【2010真题】下列命中组合情况中，一次访存过程中不可能发生的是 	（    ）。

​		A． TLB 未命中， Cache 未命中， Page 未命中

​		B． TLB 未命中， Cache 命中， Page 命中

​		C． TLB 命中， Cache 未命中， Page 命中

​		D． TLB 命中， Cache 命中， Page 未命中 

​		答案：D

​		要点：TLB 命中，Page 必命中；Page 缺失，Cache 必缺失。

23. 【2019真题】下列关于缺页处理的叙述中，错误的是 	（    ）。
    A．缺页是在地址转换时 CPU 检测到的一种异常
    B．缺页处理由操作系统提供的缺页处理程序来完成
    C．缺页处理程序根据页故障地址从外存读入所缺失的页
    D．缺页处理完成后回到发生缺页的指令的下一条指令执行 

​		答案：D

​		要点：缺页处理完成后回到发生缺页的指令继续执行。

24. 【2020真题】下列关于 TLB 和 Cache 的叙述中，错误的是	（    ）。

​		A.命中率都与程序局部性有关							B.缺失后都需要去访问主存

​		C.缺失处理都可以由硬件实现							D.都由 DRAM 存储器组成

​		答案：D

25. 【2015真题】假定编译器将赋值语句 “ x=x+3; ” 转换为指令 “add xaddr, 3”，其中， xaddr 是 x 对应的存储单元地址。若执行该指令的计算机采用页式虚拟存储管理方式，并配有相应的 TLB，且 Cache 使用直写（Write Through）方式，则完成该指令功能需要访问主存的次数至少是	（    ）。

​		A． 0 								B． 1							C． 2 							D． 3 

​		答案：B

​		要点：直写方式下，每次写入都必须将数据同时写入 Cache 和主存。

26. 【2013真题】某计算机主存地址空间大小为256 MB，按字节编址。虚拟地址空间大小为 4GB，采用页式存储管理，页面大小为 4KB，TLB (快表)采用全相联映射，有 4 个页表项，内容如下表所示

![](E:\source\jk-english\英语语法初级\图片\3_66_26题图.png)

​		则对虚拟地址 03FF F180H 进行虚实地址变换的结果是	（   ）。

​		A.015 3180H					B.003 5180H					C.TLB缺失					D.缺页

​		答案：A

​		要点：虚页号的位数，可以由虚页的个数推出；TLB 中保存的标记就是虚页号。

27. 【2022真题】某计算机主存地址为 24 位，采用分页虚拟存储管理方式，虚拟地址空间大小为 4GB, 页大小为4KB, 按字节编址。 某进程的页表部分内容如下表所示。 

![](E:\source\jk-english\英语语法初级\图片\3_67_27题图.png)

​		当 CPU 访问虚拟地址 0008 2840H 时，虚－实地址转换的结果是 	（    ）。

​		A. 得到主存地址 02 4840H		 				B. 得到主存地址 18 0840H 

​		C. 得到主存地址 01 8840H 						D. 检测到缺页异常 

​		答案：C

#### 二、综合应用题

1. 【2016真题】某计算机采用页式虚拟存储管理方式，按字节编址，虚拟地址为 32 位，物理地址为 24 位，页大小为 8KB；TLB 采用全相联映射； Cache 数据区大小为 64KB，按 2 路组相联方式组织，主存块大小为 64B。存储访问过程的示意图如下。 

![1687870569946](E:\source\jk-english\英语语法初级\图片\3_68_大题1题图.png)

​		请回答下列问题。

​	（1）图中字段 A~G 的位数各是多少？ TLB 标记字段 B 中存放的是什么信息？

​	（2）将块号为 4099 的主存块装入到 Cache 中时，所映射的 Cache 组号是多少？对应的 H 字段内容是什么？

​	（3) Cache 缺失处理的时间开销大还是缺页处理的时间开销大？为什么？ 

​		**答案：**

​	（1）页大小为 8KB，页内偏移地址为 13 位，故 A=B=32-13=19； D=13； C=24-13=11；

​		主存块大小为 64B，故 G=6。 

​		2 路组相联，每组数据区容量有 64 B×2=128B，共有 64KB/128B=512 组，故 F=9；

​		E = 24-G-F = 24-6-9 = 9。

​		因而  A=19， B=19， C=11， D=13， E=9， F=9， G=6。

​		TLB 中标记字段 B 的内容是虚页号，表示该 TLB 项对应哪个虚页的页表项。

​	（2）块号 4099=00 0001 0000 0000 0011B，因此，所映射的 Cache 组号为 0 0000 0011B=3，对应的 H 字段内容为 0 0000 1000B。 

​	（3） Cache 缺失带来的开销小，而处理缺页的开销大。 因为缺页处理需要访问磁盘，而 Cache 缺失只要访问主存。

2. 【2018真题】某计算机采用页式虚拟存储管理方式，按字节编址。CPU 进行存储访问的过程如图所示。

![](E:\source\jk-english\英语语法初级\图片\3_69_大题2题图.png)

​		根据上图回答下列问题。

​		(1) 主存物理地址占多少位？

​		(2) TLB 采用什么映射方式？TLB 用 SRAM 还是 DRAM 实现?

​		(3) Cache 采用什么映射方式？若 Cache 采用 LRU 替换算法和回写（Write Back）策略，则 Cache 每行中除数据（Data）、Tag 和有效位外，还应有哪些附加位？Cache 总容量是多少？Cache 中有效位的作用是什么？

​		(4) 若 CPU 给出的虚拟地址为 0008 C040H，则对应的物理地址是多少？是否在 Cache 中命中？说明理由，若 CPU 给出的虚拟地址为 0007 C260H，则该地址所在主存块映射到的 Cache 组号是多少?

​		**答案：**

​	（1）物理地址由实页号和页内地址拼接，因此其位数为 16+12 = 28；或直接可得 20+3+5 = 28。

​	（2） TLB 采用全相联映射，可以把页表内容调入任一块空 TLB 项中， TLB 中每项都有一个比较器，没有映射规则，只要空闲就行。 TLB 采用静态存储器 SRAM，读写速度快，但成本高，多用于容量较小的高速缓冲存器。

​	（3）图中可以看到， Cache 中每组有两行，故采用 2 路组相联映射方式。

​		因为是 2 路组相联并采用 LRU 替换算法，所以每行（或每组）需要 1 位 LRU 位；因为采用回写策略，所以每行有 1 位修改位（脏位），根据脏位判断数据是否被更新，如果脏位为 1 则需要写回内存。

​		28 位物理地址中 Tag 字段占 20 位，组索引字段占 3 位，块内偏移地址占 5 位，故 Cache 共有 2<sup>3</sup> = 8组，每组 2 行，每行有 2<sup>5</sup> = 32B；故 Cache 总容量为 8×2×(20+1+1+1+32×8) = 4464 位 = 558 字节。

​		Cache 中有效位用来指出所在 Cache 行中的信息是否有效。

​	（4）虚拟地址分为两部分：虚页号、页内地址；物理地址分为两部分：实页号、页内地址。

​		利用虚拟地址的虚页号部分去查找 TLB 表（缺失时从页表调入），将实页号取出后和虚拟地址的页内地址拼接，就形成了物理地址。

​		虚页号 008CH 恰好在 TLB 表中对应实页号 0040H（有效位为 1，说明存在），虚拟地址的后 3 位为页内地址 040H，则对应的物理地址是 0040040H。物理地址为 0040040H，其中高 20 位 00400H 为标志字段，低 5 位 00000B 为块内偏移量，中间 3 位 010B 为组号 2，因此将 00400H 与 Cache 中的第 2 组两行中的标志字段同时比较，可以看出，虽然有一个 Cache 行中的标志字段与 00400H 相等，但对应的有效位为 0，而另一 Cache 行的标志字段与 00400H 不相等，故访问 Cache 不命中。

​		因为物理地址的低 12 位与虚拟地址低 12 位相同，即为 0010 0110 0000B。根据物理地址的结构，物理地址的后八位 01100000B 的前三位 011B 是组号，因此该地址所在的主存映射到 Cache 组号为 3。 

3. 【2020真题】假定主存地址为 32 位，按字节编址，指令 Cache 和数据 Cache 与主存之间均采用 8 路组相联映射方式，直写（WriteThrough）写策略和 LRU 替换算法，主存块大小为 64B，数据区容量各为 32KB。开始时 Cache 均为空。请回答下列问题。
   (1) Cache 每一行中标记（Tag）、LRU 位各占几位？是否有修改位？
   (2) 有如下 C 语言程序段:

```c
for (k=0; k<1024 ;k++)
    s[k]=2*s[k];
```

​		若数组 s 及其变量 k 均为 int 型，int 型数据占 4B，变量 k 分配在寄存器中，数组 s 在主存中的起始地址为0080 00C0H，则该程序段执行过程中，访问数组 s 的数据 Cache 缺失次数为多少？

​		(3) 若 CPU 最先开始的访问操作是选取主存单元 0001 0003H 中的指令，简要说明从 Cache 中访问该指令的过程，包括 Cache 缺失处理过程。

​		**答案：**

​	（1）主存块大小为 64B=2<sup>6</sup> 字节，故主存地址低 6 位为块内地址， Cache 组数为 32KB/(64B×8) = 64=2<sup>6</sup>， 故主存地址中间 6 位为 Cache 组号， 主存地址中高 32-6-6=20 位为标记；

​		采用 8 路组相联映射， 故每行中 LRU 位占 3 位；

​		采用直写方式，故没有修改位。

​	（2）因为数组s的起始地址最后 6 位全为 0， 故 s 位于一个主存块开始处，共占 1024×4B/64B=64 个主存块；

​		执行程序段过程中，每个主存块中的 64B/4B=16 个数组元素依次读、写 1 次， 因而对于每个主存块，总是第一次访问缺失，以后每次命中。

​		综上， 数组 s 的数据 Cache 访问缺失次数为 64 次。
（3） 0001 0003H = 0000 0000 0000 0001 0000  000000  000011B， 根据主存地址划分可知，组索引为 0， 故该地址所在主存块被映射到指令 Cache 第 0 组； 

​		因为 Cache 初始为空，所有 Cache 行的有效位均为 0， 所以 Cache 访问缺失。此时，将该主存块取出后存入指令 Cache 第 0 组的任意一行，并将主存地址高 20 位（00010H）填人该行标记字段，设置有效位，修改 LRU 位， 最后根据块内地址 000011B 从该行中取出相应内容。

4. 【2021真题】假设计算机 M 的主存地址为 24 位，按字节编址；采用分页存储管理方式，虚拟地址为 30 位,页大小为 4 KB；TLB 采用 2 路组相联方式和 LRU 替换策略，共 8 组。请回答下列问题。

​		(1) 虚拟地址中哪几位表示虚页号？哪几位表示页内地址？

​		(2) 已知访问 TLB 时虚页号高位部分用作 TLB 标记，低位部分用作 TLB 组号，M 的虚拟地址中哪几位是 TLB 标记？哪几位是 TLB 组号？

​		(3) 假设 TLB 初始时为空，访问的虚页号依次为 10、12、16、7、26、4、12 和 20，在此过程中，哪一个虚页号对应的 TLB 表项被替换？说明理由。

​		(4) 若将 M 中的虚拟地址位数增加到 32 位，则 TLB 表项的位数增加几位？

​		**答案：**

​		注意：对于本题的 TLB，需要采用处理 Cache 的方式求解。

​	（1）按字节编址， 页面大小为 4 KB=2<sup>12</sup>B，所以页内地址为 12 位。 虚拟地址中高 30-12=18 位
表示虚页号， 虚拟地址中低 12 位表示页内地址。

​	（2）TLB 采用 2 路组相联方式，共 8=2<sup>3</sup> 组，用 3 位来 标记组号。 虚拟地址（或虚页号）中高
18-3=15 位为 TLB 标记， 虚拟地址中随后 3 位（或虚页号中低 3 位）为 TLB 组号。

​	（3）虚页号 4 对应的 TLB 表项被替换。 因为虚页号与 TLB 组号的映射关系为

​						TLB 组号＝虚页号 mod TLB 组数＝虚页号 mod 8, 

​		因此，虚页号 10,12,16, 7,26,4,12,20 映射到的 TLB 组号依次为 2,4,0,7,2,4,4,4。

​		TLB 采用 2 路组相联方式， 从上述映射到的TLB 组号序列可以看出，只有映射到 4 号组的虚页号数量大于 2, 相应虚页号依次是 12,4,12 和 20。根据 LRU 替换策略， 当访问第 20 页时， 虚页号 4 对应的TLB 表项被替换出来。

​	（4）虚拟地址位数增加到 32 位时， 虚页号增加了 32-30=2 位， 使得每个TLB 表项中的标记字段增加 2 位， 因此，每个TLB 表项的位数增加 2 位。